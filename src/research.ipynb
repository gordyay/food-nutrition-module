{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cf177d6",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f166f715",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='data/'\n",
    "api_key='ehlVSIKSMiugJZHlii3sU7OKCexe4MIlnYenGric'\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebdaf62",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd70e2d",
   "metadata": {},
   "source": [
    "## Take  a look on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e04c1794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: 17736\n",
      "rating: 8\n",
      "calories: 1858\n",
      "protein: 282\n",
      "fat: 326\n",
      "sodium: 2434\n",
      "#cakeweek: 2\n",
      "#wasteless: 2\n",
      "22-minute meals: 2\n",
      "3-ingredient recipes: 2\n",
      "30 days of groceries: 2\n",
      "advance prep required: 2\n",
      "alabama: 2\n",
      "alaska: 2\n",
      "alcoholic: 2\n",
      "almond: 2\n",
      "amaretto: 2\n",
      "anchovy: 2\n",
      "anise: 2\n",
      "anniversary: 2\n",
      "anthony bourdain: 2\n",
      "aperitif: 2\n",
      "appetizer: 2\n",
      "apple: 2\n",
      "apple juice: 2\n",
      "apricot: 2\n",
      "arizona: 2\n",
      "artichoke: 2\n",
      "arugula: 2\n",
      "asian pear: 2\n",
      "asparagus: 2\n",
      "aspen: 2\n",
      "atlanta: 2\n",
      "australia: 2\n",
      "avocado: 2\n",
      "back to school: 2\n",
      "backyard bbq: 2\n",
      "bacon: 2\n",
      "bake: 2\n",
      "banana: 2\n",
      "barley: 2\n",
      "basil: 2\n",
      "bass: 2\n",
      "bastille day: 2\n",
      "bean: 2\n",
      "beef: 2\n",
      "beef rib: 2\n",
      "beef shank: 2\n",
      "beef tenderloin: 2\n",
      "beer: 2\n",
      "beet: 2\n",
      "bell pepper: 2\n",
      "berry: 2\n",
      "beverly hills: 2\n",
      "birthday: 2\n",
      "biscuit: 2\n",
      "bitters: 2\n",
      "blackberry: 2\n",
      "blender: 2\n",
      "blue cheese: 2\n",
      "blueberry: 2\n",
      "boil: 2\n",
      "bok choy: 2\n",
      "bon appétit: 2\n",
      "bon app��tit: 2\n",
      "boston: 2\n",
      "bourbon: 2\n",
      "braise: 2\n",
      "bran: 2\n",
      "brandy: 2\n",
      "bread: 2\n",
      "breadcrumbs: 2\n",
      "breakfast: 2\n",
      "brie: 2\n",
      "brine: 2\n",
      "brisket: 2\n",
      "broccoli: 2\n",
      "broccoli rabe: 2\n",
      "broil: 2\n",
      "brooklyn: 2\n",
      "brown rice: 2\n",
      "brownie: 2\n",
      "brunch: 2\n",
      "brussel sprout: 2\n",
      "buffalo: 2\n",
      "buffet: 2\n",
      "bulgaria: 2\n",
      "bulgur: 2\n",
      "burrito: 2\n",
      "butter: 2\n",
      "buttermilk: 2\n",
      "butternut squash: 2\n",
      "butterscotch/caramel: 2\n",
      "cabbage: 2\n",
      "cake: 2\n",
      "california: 2\n",
      "calvados: 2\n",
      "cambridge: 2\n",
      "campari: 2\n",
      "camping: 2\n",
      "canada: 2\n",
      "candy: 2\n",
      "candy thermometer: 2\n",
      "cantaloupe: 2\n",
      "capers: 2\n",
      "caraway: 2\n",
      "cardamom: 2\n",
      "carrot: 2\n",
      "cashew: 2\n",
      "casserole/gratin: 2\n",
      "cauliflower: 2\n",
      "caviar: 2\n",
      "celery: 2\n",
      "chambord: 2\n",
      "champagne: 2\n",
      "chard: 2\n",
      "chartreuse: 2\n",
      "cheddar: 2\n",
      "cheese: 2\n",
      "cherry: 2\n",
      "chestnut: 2\n",
      "chicago: 2\n",
      "chicken: 2\n",
      "chickpea: 2\n",
      "chile: 2\n",
      "chile pepper: 2\n",
      "chili: 2\n",
      "chill: 2\n",
      "chive: 2\n",
      "chocolate: 2\n",
      "christmas: 2\n",
      "christmas eve: 2\n",
      "cilantro: 2\n",
      "cinco de mayo: 2\n",
      "cinnamon: 2\n",
      "citrus: 2\n",
      "clam: 2\n",
      "clove: 2\n",
      "cobbler/crumble: 2\n",
      "cocktail: 2\n",
      "cocktail party: 2\n",
      "coconut: 2\n",
      "cod: 2\n",
      "coffee: 2\n",
      "coffee grinder: 2\n",
      "cognac/armagnac: 2\n",
      "collard greens: 2\n",
      "colorado: 2\n",
      "columbus: 2\n",
      "condiment: 2\n",
      "condiment/spread: 2\n",
      "connecticut: 2\n",
      "cook like a diner: 2\n",
      "cookbook critic: 2\n",
      "cookie: 2\n",
      "cookies: 2\n",
      "coriander: 2\n",
      "corn: 2\n",
      "cornmeal: 2\n",
      "costa mesa: 2\n",
      "cottage cheese: 2\n",
      "couscous: 2\n",
      "crab: 2\n",
      "cranberry: 2\n",
      "cranberry sauce: 2\n",
      "cream cheese: 2\n",
      "créme de cacao: 2\n",
      "crêpe: 2\n",
      "cr��me de cacao: 2\n",
      "cuba: 2\n",
      "cucumber: 2\n",
      "cumin: 2\n",
      "cupcake: 2\n",
      "currant: 2\n",
      "curry: 2\n",
      "custard: 2\n",
      "dairy: 2\n",
      "dairy free: 2\n",
      "dallas: 2\n",
      "date: 2\n",
      "deep-fry: 2\n",
      "denver: 2\n",
      "dessert: 2\n",
      "digestif: 2\n",
      "dill: 2\n",
      "dinner: 2\n",
      "dip: 2\n",
      "diwali: 2\n",
      "dominican republic: 2\n",
      "dorie greenspan: 2\n",
      "double boiler: 2\n",
      "dried fruit: 2\n",
      "drink: 2\n",
      "drinks: 2\n",
      "duck: 2\n",
      "easter: 2\n",
      "eau de vie: 2\n",
      "edible gift: 2\n",
      "egg: 2\n",
      "egg nog: 2\n",
      "eggplant: 2\n",
      "egypt: 2\n",
      "emeril lagasse: 2\n",
      "endive: 2\n",
      "engagement party: 2\n",
      "england: 2\n",
      "entertaining: 2\n",
      "epi + ushg: 2\n",
      "epi loves the microwave: 2\n",
      "escarole: 2\n",
      "fall: 2\n",
      "family reunion: 2\n",
      "fat free: 2\n",
      "father's day: 2\n",
      "fennel: 2\n",
      "feta: 2\n",
      "fig: 2\n",
      "fish: 2\n",
      "flaming hot summer: 2\n",
      "flat bread: 2\n",
      "florida: 2\n",
      "fontina: 2\n",
      "food processor: 2\n",
      "fortified wine: 2\n",
      "fourth of july: 2\n",
      "france: 2\n",
      "frangelico: 2\n",
      "frankenrecipe: 2\n",
      "freeze/chill: 2\n",
      "freezer food: 2\n",
      "friendsgiving: 2\n",
      "frittata: 2\n",
      "fritter: 2\n",
      "frozen dessert: 2\n",
      "fruit: 2\n",
      "fruit juice: 2\n",
      "fry: 2\n",
      "game: 2\n",
      "garlic: 2\n",
      "georgia: 2\n",
      "germany: 2\n",
      "gin: 2\n",
      "ginger: 2\n",
      "goat cheese: 2\n",
      "goose: 2\n",
      "gouda: 2\n",
      "gourmet: 2\n",
      "graduation: 2\n",
      "grains: 2\n",
      "grand marnier: 2\n",
      "granola: 2\n",
      "grape: 2\n",
      "grapefruit: 2\n",
      "grappa: 2\n",
      "green bean: 2\n",
      "green onion/scallion: 2\n",
      "grill: 2\n",
      "grill/barbecue: 2\n",
      "ground beef: 2\n",
      "ground lamb: 2\n",
      "guam: 2\n",
      "guava: 2\n",
      "haiti: 2\n",
      "halibut: 2\n",
      "halloween: 2\n",
      "ham: 2\n",
      "hamburger: 2\n",
      "hanukkah: 2\n",
      "harpercollins: 2\n",
      "hawaii: 2\n",
      "hazelnut: 2\n",
      "healdsburg: 2\n",
      "healthy: 2\n",
      "herb: 2\n",
      "high fiber: 2\n",
      "hollywood: 2\n",
      "hominy/cornmeal/masa: 2\n",
      "honey: 2\n",
      "honeydew: 2\n",
      "hors d'oeuvre: 2\n",
      "horseradish: 2\n",
      "hot drink: 2\n",
      "hot pepper: 2\n",
      "house & garden: 2\n",
      "house cocktail: 2\n",
      "houston: 2\n",
      "hummus: 2\n",
      "ice cream: 2\n",
      "ice cream machine: 2\n",
      "iced coffee: 2\n",
      "iced tea: 2\n",
      "idaho: 2\n",
      "illinois: 2\n",
      "indiana: 2\n",
      "iowa: 2\n",
      "ireland: 2\n",
      "israel: 2\n",
      "italy: 2\n",
      "jalapeño: 2\n",
      "jam or jelly: 2\n",
      "jamaica: 2\n",
      "japan: 2\n",
      "jerusalem artichoke: 2\n",
      "juicer: 2\n",
      "jícama: 2\n",
      "kahlúa: 2\n",
      "kale: 2\n",
      "kansas: 2\n",
      "kansas city: 2\n",
      "kentucky: 2\n",
      "kentucky derby: 2\n",
      "kid-friendly: 2\n",
      "kidney friendly: 2\n",
      "kirsch: 2\n",
      "kitchen olympics: 2\n",
      "kiwi: 2\n",
      "kosher: 2\n",
      "kosher for passover: 2\n",
      "kumquat: 2\n",
      "kwanzaa: 2\n",
      "labor day: 2\n",
      "lamb: 2\n",
      "lamb chop: 2\n",
      "lamb shank: 2\n",
      "lancaster: 2\n",
      "las vegas: 2\n",
      "lasagna: 2\n",
      "leafy green: 2\n",
      "leek: 2\n",
      "legume: 2\n",
      "lemon: 2\n",
      "lemon juice: 2\n",
      "lemongrass: 2\n",
      "lentil: 2\n",
      "lettuce: 2\n",
      "lima bean: 2\n",
      "lime: 2\n",
      "lime juice: 2\n",
      "lingonberry: 2\n",
      "liqueur: 2\n",
      "lobster: 2\n",
      "london: 2\n",
      "long beach: 2\n",
      "los angeles: 2\n",
      "louisiana: 2\n",
      "louisville: 2\n",
      "low cal: 2\n",
      "low carb: 2\n",
      "low cholesterol: 2\n",
      "low fat: 2\n",
      "low sodium: 2\n",
      "low sugar: 2\n",
      "low/no sugar: 2\n",
      "lunar new year: 2\n",
      "lunch: 2\n",
      "lychee: 2\n",
      "macadamia nut: 2\n",
      "macaroni and cheese: 2\n",
      "maine: 2\n",
      "mandoline: 2\n",
      "mango: 2\n",
      "maple syrup: 2\n",
      "mardi gras: 2\n",
      "margarita: 2\n",
      "marinade: 2\n",
      "marinate: 2\n",
      "marsala: 2\n",
      "marscarpone: 2\n",
      "marshmallow: 2\n",
      "martini: 2\n",
      "maryland: 2\n",
      "massachusetts: 2\n",
      "mayonnaise: 2\n",
      "meat: 2\n",
      "meatball: 2\n",
      "meatloaf: 2\n",
      "melon: 2\n",
      "mexico: 2\n",
      "mezcal: 2\n",
      "miami: 2\n",
      "michigan: 2\n",
      "microwave: 2\n",
      "midori: 2\n",
      "milk/cream: 2\n",
      "minneapolis: 2\n",
      "minnesota: 2\n",
      "mint: 2\n",
      "mississippi: 2\n",
      "missouri: 2\n",
      "mixer: 2\n",
      "molasses: 2\n",
      "monterey jack: 2\n",
      "mortar and pestle: 2\n",
      "mother's day: 2\n",
      "mozzarella: 2\n",
      "muffin: 2\n",
      "mushroom: 2\n",
      "mussel: 2\n",
      "mustard: 2\n",
      "mustard greens: 2\n",
      "nancy silverton: 2\n",
      "nebraska: 2\n",
      "nectarine: 2\n",
      "new hampshire: 2\n",
      "new jersey: 2\n",
      "new mexico: 2\n",
      "new orleans: 2\n",
      "new year's day: 2\n",
      "new year's eve: 2\n",
      "new york: 2\n",
      "no meat, no problem: 2\n",
      "no sugar added: 2\n",
      "no-cook: 2\n",
      "non-alcoholic: 2\n",
      "noodle: 2\n",
      "north carolina: 2\n",
      "nut: 2\n",
      "nutmeg: 2\n",
      "oat: 2\n",
      "oatmeal: 2\n",
      "octopus: 2\n",
      "ohio: 2\n",
      "oklahoma: 2\n",
      "okra: 2\n",
      "oktoberfest: 2\n",
      "olive: 2\n",
      "omelet: 2\n",
      "one-pot meal: 2\n",
      "onion: 2\n",
      "orange: 2\n",
      "orange juice: 2\n",
      "oregano: 2\n",
      "oregon: 2\n",
      "organic: 2\n",
      "orzo: 2\n",
      "oscars: 2\n",
      "oyster: 2\n",
      "pacific palisades: 2\n",
      "paleo: 2\n",
      "pan-fry: 2\n",
      "pancake: 2\n",
      "papaya: 2\n",
      "paprika: 2\n",
      "parade: 2\n",
      "paris: 2\n",
      "parmesan: 2\n",
      "parsley: 2\n",
      "parsnip: 2\n",
      "party: 2\n",
      "pasadena: 2\n",
      "passion fruit: 2\n",
      "passover: 2\n",
      "pasta: 2\n",
      "pasta maker: 2\n",
      "pastry: 2\n",
      "pea: 2\n",
      "peach: 2\n",
      "peanut: 2\n",
      "peanut butter: 2\n",
      "peanut free: 2\n",
      "pear: 2\n",
      "pecan: 2\n",
      "pennsylvania: 2\n",
      "pepper: 2\n",
      "pernod: 2\n",
      "persian new year: 2\n",
      "persimmon: 2\n",
      "peru: 2\n",
      "pescatarian: 2\n",
      "philippines: 2\n",
      "phyllo/puff pastry dough: 2\n",
      "pickles: 2\n",
      "picnic: 2\n",
      "pie: 2\n",
      "pine nut: 2\n",
      "pineapple: 2\n",
      "pistachio: 2\n",
      "pittsburgh: 2\n",
      "pizza: 2\n",
      "plantain: 2\n",
      "plum: 2\n",
      "poach: 2\n",
      "poblano: 2\n",
      "poker/game night: 2\n",
      "pomegranate: 2\n",
      "pomegranate juice: 2\n",
      "poppy: 2\n",
      "pork: 2\n",
      "pork chop: 2\n",
      "pork rib: 2\n",
      "pork tenderloin: 2\n",
      "port: 2\n",
      "portland: 2\n",
      "pot pie: 2\n",
      "potato: 2\n",
      "potato salad: 2\n",
      "potluck: 2\n",
      "poultry: 2\n",
      "poultry sausage: 2\n",
      "pressure cooker: 2\n",
      "prosciutto: 2\n",
      "providence: 2\n",
      "prune: 2\n",
      "pumpkin: 2\n",
      "punch: 2\n",
      "purim: 2\n",
      "quail: 2\n",
      "quiche: 2\n",
      "quick & easy: 2\n",
      "quick and healthy: 2\n",
      "quince: 2\n",
      "quinoa: 2\n",
      "rabbit: 2\n",
      "rack of lamb: 2\n",
      "radicchio: 2\n",
      "radish: 2\n",
      "raisin: 2\n",
      "ramadan: 2\n",
      "ramekin: 2\n",
      "raspberry: 2\n",
      "raw: 2\n",
      "red wine: 2\n",
      "rhode island: 2\n",
      "rhubarb: 2\n",
      "rice: 2\n",
      "ricotta: 2\n",
      "roast: 2\n",
      "root vegetable: 2\n",
      "rosemary: 2\n",
      "rosh hashanah/yom kippur: 2\n",
      "rosé: 2\n",
      "rub: 2\n",
      "rum: 2\n",
      "rutabaga: 2\n",
      "rye: 2\n",
      "saffron: 2\n",
      "sage: 2\n",
      "sake: 2\n",
      "salad: 2\n",
      "salad dressing: 2\n",
      "salmon: 2\n",
      "salsa: 2\n",
      "san francisco: 2\n",
      "sandwich: 2\n",
      "sandwich theory: 2\n",
      "sangria: 2\n",
      "santa monica: 2\n",
      "sardine: 2\n",
      "sauce: 2\n",
      "sausage: 2\n",
      "sauté: 2\n",
      "scallop: 2\n",
      "scotch: 2\n",
      "seafood: 2\n",
      "seattle: 2\n",
      "seed: 2\n",
      "self: 2\n",
      "semolina: 2\n",
      "sesame: 2\n",
      "sesame oil: 2\n",
      "shallot: 2\n",
      "shavuot: 2\n",
      "shellfish: 2\n",
      "sherry: 2\n",
      "shower: 2\n",
      "shrimp: 2\n",
      "side: 2\n",
      "simmer: 2\n",
      "skewer: 2\n",
      "slow cooker: 2\n",
      "smoker: 2\n",
      "smoothie: 2\n",
      "snapper: 2\n",
      "sorbet: 2\n",
      "soufflé/meringue: 2\n",
      "soup/stew: 2\n",
      "sour cream: 2\n",
      "sourdough: 2\n",
      "south carolina: 2\n",
      "soy: 2\n",
      "soy free: 2\n",
      "soy sauce: 2\n",
      "spain: 2\n",
      "sparkling wine: 2\n",
      "spice: 2\n",
      "spinach: 2\n",
      "spirit: 2\n",
      "spring: 2\n",
      "spritzer: 2\n",
      "squash: 2\n",
      "squid: 2\n",
      "st. louis: 2\n",
      "st. patrick's day: 2\n",
      "steak: 2\n",
      "steam: 2\n",
      "stew: 2\n",
      "stir-fry: 2\n",
      "stock: 2\n",
      "strawberry: 2\n",
      "stuffing/dressing: 2\n",
      "sugar conscious: 2\n",
      "sugar snap pea: 2\n",
      "sukkot: 2\n",
      "summer: 2\n",
      "super bowl: 2\n",
      "suzanne goin: 2\n",
      "sweet potato/yam: 2\n",
      "swiss cheese: 2\n",
      "switzerland: 2\n",
      "swordfish: 2\n",
      "taco: 2\n",
      "tailgating: 2\n",
      "tamarind: 2\n",
      "tangerine: 2\n",
      "tapioca: 2\n",
      "tarragon: 2\n",
      "tart: 2\n",
      "tea: 2\n",
      "tennessee: 2\n",
      "tequila: 2\n",
      "tested & improved: 2\n",
      "texas: 2\n",
      "thanksgiving: 2\n",
      "thyme: 2\n",
      "tilapia: 2\n",
      "tofu: 2\n",
      "tomatillo: 2\n",
      "tomato: 2\n",
      "tortillas: 2\n",
      "tree nut: 2\n",
      "tree nut free: 2\n",
      "triple sec: 2\n",
      "tropical fruit: 2\n",
      "trout: 2\n",
      "tuna: 2\n",
      "turnip: 2\n",
      "utah: 2\n",
      "valentine's day: 2\n",
      "vanilla: 2\n",
      "veal: 2\n",
      "vegan: 2\n",
      "vegetable: 2\n",
      "vegetarian: 2\n",
      "venison: 2\n",
      "vermont: 2\n",
      "vermouth: 2\n",
      "vinegar: 2\n",
      "virginia: 2\n",
      "vodka: 2\n",
      "waffle: 2\n",
      "walnut: 2\n",
      "wasabi: 2\n",
      "washington: 2\n",
      "washington, d.c.: 2\n",
      "watercress: 2\n",
      "watermelon: 2\n",
      "wedding: 2\n",
      "weelicious: 2\n",
      "west virginia: 2\n",
      "westwood: 2\n",
      "wheat/gluten-free: 2\n",
      "whiskey: 2\n",
      "white wine: 2\n",
      "whole wheat: 2\n",
      "wild rice: 2\n",
      "windsor: 2\n",
      "wine: 2\n",
      "winter: 2\n",
      "wisconsin: 2\n",
      "wok: 2\n",
      "yellow squash: 2\n",
      "yogurt: 2\n",
      "yonkers: 2\n",
      "yuca: 2\n",
      "zucchini: 2\n",
      "cookbooks: 2\n",
      "leftovers: 2\n",
      "snack: 2\n",
      "snack week: 2\n",
      "turkey: 2\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_csv(f\"{data_path}epi_r.csv\")\n",
    "for name, count in df.nunique().items():\n",
    "    print(f\"{name}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860a3825",
   "metadata": {},
   "source": [
    "The dataset have target feature:\n",
    "```rating```.\n",
    "\n",
    "There is also features: ```title, calories, protein, fat, sodium```\n",
    "\n",
    "\n",
    "\n",
    "Dataset have 2 categorical features after the One-Hot Encoding conversion.\n",
    "\n",
    "first categorical feature is:\n",
    "\n",
    "Ingredients: ```almond, anchovy, apple, avocado, bacon```\n",
    "\n",
    "second categorical feature is tags\n",
    "\n",
    "The tags may contain:\n",
    "* Recipe characteristics: ```#cakeweek, #wasteless, 22-minute meals, 3-ingredient recipes...```\n",
    "\n",
    "* Geographical affiliation: ```alabama, arizona, boston, france, italy...```\n",
    "\n",
    "* Dietary restrictions and features: ```dairy free, gluten free, vegan...```\n",
    "\n",
    "* Cooking methods: ```bake, boil, grill, slow cooker...```\n",
    "\n",
    "* Holidays and events: ```christmas, halloween, valentine's day...```\n",
    "\n",
    "* Machinery and tools: ```blender, food processor, pressure cooker, microwave...```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb48838",
   "metadata": {},
   "source": [
    "## Let's sort columns in the dataset, and get nutrients for ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb3279b",
   "metadata": {},
   "source": [
    "### this is list of nutrients, what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ecb71ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrients_list = [\n",
    "    # Основные макронутриенты \n",
    "    \"Total lipid (fat)\",\n",
    "    \"Fatty acids, total saturated\",\n",
    "    \"Fatty acids, total monounsaturated\",\n",
    "    \"Fatty acids, total polyunsaturated\",\n",
    "    \"Fatty acids, total trans\",\n",
    "    \"Cholesterol\",\n",
    "    \"Carbohydrate, by difference\",\n",
    "    \"Sodium, Na\", \n",
    "    \"Fiber, total dietary\",\n",
    "    \"Protein\",\n",
    "    \"Sugars, Total\",  \n",
    "    \"Energy\", \n",
    "    \"Vitamin A, RAE\",  \n",
    "    \"Vitamin C, total ascorbic acid\", \n",
    "    \"Vitamin D (D2 + D3)\",\n",
    "    \"Vitamin E (alpha-tocopherol)\",\n",
    "    \"Vitamin K (phylloquinone)\",\n",
    "    \"Thiamin\",\n",
    "    \"Riboflavin\",\n",
    "    \"Niacin\",\n",
    "    \"Vitamin B-6\",\n",
    "    \"Folate, total\",\n",
    "    \"Vitamin B-12\",\n",
    "    \n",
    "    # Минералы\n",
    "    \"Calcium, Ca\",\n",
    "    \"Iron, Fe\",\n",
    "    \"Phosphorus, P\",\n",
    "    \"Magnesium, Mg\",\n",
    "    \"Zinc, Zn\",\n",
    "    \"Copper, Cu\",\n",
    "    \"Manganese, Mn\",\n",
    "    \"Selenium, Se\",\n",
    "    \"Potassium, K\",\n",
    "    \n",
    "    # Специфичные компоненты \n",
    "    \"Ash\",\n",
    "    \"Nitrogen\",\n",
    "    \"Water\",\n",
    "    \n",
    "    # Разные формы сахаров\n",
    "    \"Fructose\",\n",
    "    \"Glucose\",\n",
    "    \"Sucrose\",\n",
    "    \"Galactose\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be624830",
   "metadata": {},
   "source": [
    "### Funcs for primary sort ingredients and get cache for nutrients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "062b7635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "def load_nutrients_cache(path_to_file):\n",
    "    try:\n",
    "        with open(path_to_file, 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                return json.load(f)\n",
    "            except:\n",
    "                return {}\n",
    "    except:\n",
    "        return {}\n",
    "def save_to_cache(path_to_file, ingredient, nutrient_dict, cache):\n",
    "    cache[ingredient]=nutrient_dict\n",
    "    with open(path_to_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(cache, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "def get_nutrients_info(ingredient):\n",
    "    ingredient_info=None\n",
    "    params = {\n",
    "        \"query\": f'\"{ingredient}\"',\n",
    "        \"api_key\": api_key,\n",
    "        \"dataType\": [\"Foundation\"]  \n",
    "    }\n",
    "    cache=load_nutrients_cache(f\"{data_path}ingridient_nutr_cache.json\")\n",
    "    non_ingredient_cache=load_nutrients_cache(f\"{data_path}not_ingridient_cache.json\")\n",
    "    if ingredient in cache:\n",
    "        return cache[ingredient]\n",
    "    elif ingredient not in non_ingredient_cache:\n",
    "        response = requests.get('https://api.nal.usda.gov/fdc/v1/foods/search', params=params)\n",
    "        if response.status_code == 200:\n",
    "            ingredient_info = response.json().get('foods')\n",
    "            if ingredient_info and ingredient_info[0].get('score') < 200:\n",
    "                ingredient_info=None\n",
    "            if ingredient_info:\n",
    "                ingredient_info=ingredient_info[0].get('foodNutrients')\n",
    "                nutrient_df=pd.json_normalize(ingredient_info)[['nutrientName','unitName','value']]\n",
    "                nutrient_dict=nutrient_df[nutrient_df['nutrientName'].isin(nutrients_list)].to_dict()       \n",
    "                save_to_cache(f\"{data_path}ingridient_nutr_cache.json\",ingredient, nutrient_dict, cache)\n",
    "    if not ingredient_info:\n",
    "        save_to_cache(f\"{data_path}not_ingridient_cache.json\",ingredient, ingredient_info, non_ingredient_cache)\n",
    "    return ingredient_info\n",
    "def is_ingredient(ingredient):\n",
    "    data=get_nutrients_info(ingredient)\n",
    "    return True if data else False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87648796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a list of possible ingredients\n",
      "['fat', 'sodium', 'almond', 'apple', 'apple juice', 'apricot', 'arugula', 'asparagus', 'avocado', 'bacon', 'banana', 'barley', 'bean', 'beef', 'beef tenderloin', 'beet', 'blackberry', 'blueberry', 'boil', 'bok choy', 'braise', 'bran', 'bread', 'breakfast', 'broccoli', 'broil', 'brussel sprout', 'bulgur', 'butter', 'buttermilk', 'cabbage', 'cantaloupe', 'carrot', 'cashew', 'cauliflower', 'celery', 'cheddar', 'cherry', 'chestnut', 'chicken', 'chickpea', 'cobbler/crumble', 'coconut', 'cod', 'cookie', 'cookies', 'corn', 'cottage cheese', 'crab', 'cranberry', 'cream cheese', 'cucumber', 'dill', 'egg', 'eggplant', 'fat free', 'feta', 'fig', 'fish', 'garlic', 'grains', 'grape', 'grapefruit', 'green onion/scallion', 'ham', 'hazelnut', 'hominy/cornmeal/masa', 'honeydew', 'hummus', 'kale', 'kiwi', 'kosher', 'lamb', 'leek', 'lentil', 'lettuce', 'low fat', 'low/no sugar', 'macadamia nut', 'mango', 'meat', 'melon', 'milk/cream', 'monterey jack', 'mozzarella', 'mushroom', 'mustard', 'nectarine', 'no sugar added', 'no-cook', 'nut', 'oat', 'oatmeal', 'olive', 'onion', 'orange', 'orange juice', 'oyster', 'parmesan', 'pasta', 'pastry', 'pea', 'peach', 'peanut', 'peanut butter', 'pear', 'pecan', 'pepper', 'pickles', 'pie', 'pine nut', 'pineapple', 'pistachio', 'plantain', 'plum', 'pomegranate', 'pork', 'pork chop', 'potato', 'prune', 'pumpkin', 'quinoa', 'raisin', 'raspberry', 'raw', 'rice', 'ricotta', 'rutabaga', 'rye', 'salmon', 'salsa', 'sausage', 'seed', 'semolina', 'sesame', 'shallot', 'shrimp', 'soy', 'spinach', 'squash', 'steak', 'strawberry', 'stuffing/dressing', 'summer', 'sweet potato/yam', 'tart', 'tilapia', 'tomatillo', 'tomato', 'tuna', 'walnut', 'wheat/gluten-free', 'whole wheat', 'wild rice', 'winter', 'yogurt', 'zucchini', 'turkey']\n"
     ]
    }
   ],
   "source": [
    "features =[]\n",
    "for column in df.columns:\n",
    "    for ingredients in column.split(\"/\"):\n",
    "        if is_ingredient(ingredients):\n",
    "            features.append(column)\n",
    "            break\n",
    "print(\"a list of possible ingredients\")\n",
    "print (features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "138b1bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a list of possible non ingredients\n",
      "['title', 'rating', 'calories', 'protein', '#cakeweek', '#wasteless', '22-minute meals', '3-ingredient recipes', '30 days of groceries', 'advance prep required', 'alabama', 'alaska', 'alcoholic', 'amaretto', 'anchovy', 'anise', 'anniversary', 'anthony bourdain', 'aperitif', 'appetizer', 'arizona', 'artichoke', 'asian pear', 'aspen', 'atlanta', 'australia', 'back to school', 'backyard bbq', 'bake', 'basil', 'bass', 'bastille day', 'beef rib', 'beef shank', 'beer', 'bell pepper', 'berry', 'beverly hills', 'birthday', 'biscuit', 'bitters', 'blender', 'blue cheese', 'bon appétit', 'bon app��tit', 'boston', 'bourbon', 'brandy', 'breadcrumbs', 'brie', 'brine', 'brisket', 'broccoli rabe', 'brooklyn', 'brown rice', 'brownie', 'brunch', 'buffalo', 'buffet', 'bulgaria', 'burrito', 'butternut squash', 'butterscotch/caramel', 'cake', 'california', 'calvados', 'cambridge', 'campari', 'camping', 'canada', 'candy', 'candy thermometer', 'capers', 'caraway', 'cardamom', 'casserole/gratin', 'caviar', 'chambord', 'champagne', 'chard', 'chartreuse', 'cheese', 'chicago', 'chile', 'chile pepper', 'chili', 'chill', 'chive', 'chocolate', 'christmas', 'christmas eve', 'cilantro', 'cinco de mayo', 'cinnamon', 'citrus', 'clam', 'clove', 'cobbler/crumble', 'cocktail', 'cocktail party', 'coffee', 'coffee grinder', 'cognac/armagnac', 'collard greens', 'colorado', 'columbus', 'condiment', 'condiment/spread', 'connecticut', 'cook like a diner', 'cookbook critic', 'coriander', 'cornmeal', 'costa mesa', 'couscous', 'cranberry sauce', 'créme de cacao', 'crêpe', 'cr��me de cacao', 'cuba', 'cumin', 'cupcake', 'currant', 'curry', 'custard', 'dairy', 'dairy free', 'dallas', 'date', 'deep-fry', 'denver', 'dessert', 'digestif', 'dinner', 'dip', 'diwali', 'dominican republic', 'dorie greenspan', 'double boiler', 'dried fruit', 'drink', 'drinks', 'duck', 'easter', 'eau de vie', 'edible gift', 'egg nog', 'egypt', 'emeril lagasse', 'endive', 'engagement party', 'england', 'entertaining', 'epi + ushg', 'epi loves the microwave', 'escarole', 'fall', 'family reunion', \"father's day\", 'fennel', 'flaming hot summer', 'flat bread', 'florida', 'fontina', 'food processor', 'fortified wine', 'fourth of july', 'france', 'frangelico', 'frankenrecipe', 'freeze/chill', 'freezer food', 'friendsgiving', 'frittata', 'fritter', 'frozen dessert', 'fruit', 'fruit juice', 'fry', 'game', 'georgia', 'germany', 'gin', 'ginger', 'goat cheese', 'goose', 'gouda', 'gourmet', 'graduation', 'grand marnier', 'granola', 'grappa', 'green bean', 'grill', 'grill/barbecue', 'ground beef', 'ground lamb', 'guam', 'guava', 'haiti', 'halibut', 'halloween', 'hamburger', 'hanukkah', 'harpercollins', 'hawaii', 'healdsburg', 'healthy', 'herb', 'high fiber', 'hollywood', 'hominy/cornmeal/masa', 'honey', \"hors d'oeuvre\", 'horseradish', 'hot drink', 'hot pepper', 'house & garden', 'house cocktail', 'houston', 'ice cream', 'ice cream machine', 'iced coffee', 'iced tea', 'idaho', 'illinois', 'indiana', 'iowa', 'ireland', 'israel', 'italy', 'jalapeño', 'jam or jelly', 'jamaica', 'japan', 'jerusalem artichoke', 'juicer', 'jícama', 'kahlúa', 'kansas', 'kansas city', 'kentucky', 'kentucky derby', 'kid-friendly', 'kidney friendly', 'kirsch', 'kitchen olympics', 'kosher for passover', 'kumquat', 'kwanzaa', 'labor day', 'lamb chop', 'lamb shank', 'lancaster', 'las vegas', 'lasagna', 'leafy green', 'legume', 'lemon', 'lemon juice', 'lemongrass', 'lima bean', 'lime', 'lime juice', 'lingonberry', 'liqueur', 'lobster', 'london', 'long beach', 'los angeles', 'louisiana', 'louisville', 'low cal', 'low carb', 'low cholesterol', 'low sodium', 'low sugar', 'lunar new year', 'lunch', 'lychee', 'macaroni and cheese', 'maine', 'mandoline', 'maple syrup', 'mardi gras', 'margarita', 'marinade', 'marinate', 'marsala', 'marscarpone', 'marshmallow', 'martini', 'maryland', 'massachusetts', 'mayonnaise', 'meatball', 'meatloaf', 'mexico', 'mezcal', 'miami', 'michigan', 'microwave', 'midori', 'milk/cream', 'minneapolis', 'minnesota', 'mint', 'mississippi', 'missouri', 'mixer', 'molasses', 'mortar and pestle', \"mother's day\", 'muffin', 'mussel', 'mustard greens', 'nancy silverton', 'nebraska', 'new hampshire', 'new jersey', 'new mexico', 'new orleans', \"new year's day\", \"new year's eve\", 'new york', 'no meat, no problem', 'non-alcoholic', 'noodle', 'north carolina', 'nutmeg', 'octopus', 'ohio', 'oklahoma', 'okra', 'oktoberfest', 'omelet', 'one-pot meal', 'oregano', 'oregon', 'organic', 'orzo', 'oscars', 'pacific palisades', 'paleo', 'pan-fry', 'pancake', 'papaya', 'paprika', 'parade', 'paris', 'parsley', 'parsnip', 'party', 'pasadena', 'passion fruit', 'passover', 'pasta maker', 'peanut free', 'pennsylvania', 'pernod', 'persian new year', 'persimmon', 'peru', 'pescatarian', 'philippines', 'phyllo/puff pastry dough', 'picnic', 'pittsburgh', 'pizza', 'poach', 'poblano', 'poker/game night', 'pomegranate juice', 'poppy', 'pork rib', 'pork tenderloin', 'port', 'portland', 'pot pie', 'potato salad', 'potluck', 'poultry', 'poultry sausage', 'pressure cooker', 'prosciutto', 'providence', 'punch', 'purim', 'quail', 'quiche', 'quick & easy', 'quick and healthy', 'quince', 'rabbit', 'rack of lamb', 'radicchio', 'radish', 'ramadan', 'ramekin', 'red wine', 'rhode island', 'rhubarb', 'roast', 'root vegetable', 'rosemary', 'rosh hashanah/yom kippur', 'rosé', 'rub', 'rum', 'saffron', 'sage', 'sake', 'salad', 'salad dressing', 'san francisco', 'sandwich', 'sandwich theory', 'sangria', 'santa monica', 'sardine', 'sauce', 'sauté', 'scallop', 'scotch', 'seafood', 'seattle', 'self', 'sesame oil', 'shavuot', 'shellfish', 'sherry', 'shower', 'side', 'simmer', 'skewer', 'slow cooker', 'smoker', 'smoothie', 'snapper', 'sorbet', 'soufflé/meringue', 'soup/stew', 'sour cream', 'sourdough', 'south carolina', 'soy free', 'soy sauce', 'spain', 'sparkling wine', 'spice', 'spirit', 'spring', 'spritzer', 'squid', 'st. louis', \"st. patrick's day\", 'steam', 'stew', 'stir-fry', 'stock', 'stuffing/dressing', 'sugar conscious', 'sugar snap pea', 'sukkot', 'super bowl', 'suzanne goin', 'sweet potato/yam', 'swiss cheese', 'switzerland', 'swordfish', 'taco', 'tailgating', 'tamarind', 'tangerine', 'tapioca', 'tarragon', 'tea', 'tennessee', 'tequila', 'tested & improved', 'texas', 'thanksgiving', 'thyme', 'tofu', 'tortillas', 'tree nut', 'tree nut free', 'triple sec', 'tropical fruit', 'trout', 'turnip', 'utah', \"valentine's day\", 'vanilla', 'veal', 'vegan', 'vegetable', 'vegetarian', 'venison', 'vermont', 'vermouth', 'vinegar', 'virginia', 'vodka', 'waffle', 'wasabi', 'washington', 'washington, d.c.', 'watercress', 'watermelon', 'wedding', 'weelicious', 'west virginia', 'westwood', 'wheat/gluten-free', 'whiskey', 'white wine', 'windsor', 'wine', 'wisconsin', 'wok', 'yellow squash', 'yonkers', 'yuca', 'cookbooks', 'leftovers', 'snack', 'snack week']\n"
     ]
    }
   ],
   "source": [
    "non_ingreedients = []\n",
    "for column in df.columns:\n",
    "    for non_ingreedient in column.split(\"/\"):\n",
    "        if not is_ingredient(non_ingreedient):\n",
    "            non_ingreedients.append(column)\n",
    "            break\n",
    "print(\"a list of possible non ingredients\")\n",
    "print (non_ingreedients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4cdc80",
   "metadata": {},
   "source": [
    "This API method doesn't work very well, so we'll sort the features manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa4485e",
   "metadata": {},
   "source": [
    "remove non_ingredients from features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2340ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_ingredients = [\n",
    "    'fat',               \n",
    "    'sodium',            \n",
    "    'boil',              \n",
    "    'braise',            \n",
    "    'broil',            \n",
    "    'breakfast',        \n",
    "    'cobbler/crumble',  \n",
    "    'cookie',           \n",
    "    'cookies',        \n",
    "    'fat free',        \n",
    "    'kosher',      \n",
    "    'low fat',          \n",
    "    'low/no sugar',    \n",
    "    'no sugar added',   \n",
    "    'no-cook',     \n",
    "    'raw',             \n",
    "    'stuffing/dressing',\n",
    "    'summer',       \n",
    "    'winter',         \n",
    "    'wheat/gluten-free'\n",
    "]\n",
    "for value in non_ingredients:\n",
    "    if value in features:\n",
    "        if value not in df.columns:\n",
    "            print(f\"problem with: {value}\")\n",
    "        features.remove(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385d8990",
   "metadata": {},
   "source": [
    "add actually ingredients from dataset to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90e34385",
   "metadata": {},
   "outputs": [],
   "source": [
    "actually_ingredients=actually_ingredients = [\n",
    "    'anchovy', 'anise', 'apple juice', 'artichoke',\n",
    "    'asian pear', 'basil', 'bass', 'beef rib',\n",
    "    'beef shank', 'beer', 'bell pepper', 'berry',\n",
    "    'bitters', 'blue cheese', 'brie', 'brisket',\n",
    "    'broccoli rabe', 'brown rice', 'brownie', 'butternut squash',\n",
    "    'butterscotch/caramel', 'cake', 'calvados', 'capers',\n",
    "    'caraway', 'cardamom', 'caviar', 'chard',\n",
    "    'cheese', 'chile', 'chile pepper', 'chili',\n",
    "    'chive', 'chocolate', 'cilantro', 'cinnamon',\n",
    "    'citrus', 'clam', 'clove', 'coffee',\n",
    "    'collard greens', 'cornmeal', 'couscous', 'cranberry sauce',\n",
    "    'crêpe', 'currant', 'curry', 'custard',\n",
    "    'date', 'dried fruit', 'duck', 'egg nog',\n",
    "    'endive', 'escarole', 'fennel', 'flat bread',\n",
    "    'fontina', 'fruit juice', 'ginger', 'goat cheese',\n",
    "    'goose', 'gouda', 'granola', 'green bean',\n",
    "    'ground beef', 'ground lamb', 'guava', 'halibut',\n",
    "    'hamburger', 'herb', 'hominy/cornmeal/masa', 'honey',\n",
    "    'horseradish', 'ice cream', 'iced coffee', 'iced tea',\n",
    "    'jalapeño', 'jam or jelly', 'jerusalem artichoke', 'jícama',\n",
    "    'kumquat', 'lamb chop', 'lamb shank', 'lasagna',\n",
    "    'leafy green', 'legume', 'lemon', 'lemon juice',\n",
    "    'lemongrass', 'lima bean', 'lime', 'lime juice',\n",
    "    'lingonberry', 'lobster', 'macaroni and cheese', 'maple syrup',\n",
    "    'mayonnaise', 'meatball', 'meatloaf', 'milk/cream',\n",
    "    'mint', 'molasses', 'muffin', 'mussel',\n",
    "    'mustard greens', 'noodle', 'nutmeg', 'octopus',\n",
    "    'okra', 'omelet', 'oregano', 'orzo',\n",
    "    'papaya', 'paprika', 'parsley', 'parsnip',\n",
    "    'passion fruit', 'persimmon', 'phyllo/puff pastry dough', 'poblano',\n",
    "    'pomegranate juice', 'poppy', 'pork rib', 'pork tenderloin',\n",
    "    'pot pie', 'potato salad', 'prosciutto', 'quail',\n",
    "    'quiche', 'quince', 'rabbit', 'rack of lamb',\n",
    "    'radicchio', 'radish', 'rhubarb', 'rosemary',\n",
    "    'rosé', 'rum', 'saffron', 'sage',\n",
    "    'sake', 'salad dressing', 'sardine', 'scallop',\n",
    "    'scotch', 'sesame oil', 'shellfish', 'sherry',\n",
    "    'snapper', 'sorbet', 'soufflé/meringue', 'soup/stew',\n",
    "    'sour cream', 'sourdough', 'soy sauce', 'spice',\n",
    "    'squid', 'stock', 'stuffing/dressing', 'sugar snap pea',\n",
    "    'sweet potato/yam', 'swiss cheese', 'swordfish', 'tamarind',\n",
    "    'tangerine', 'tapioca', 'tarragon', 'tea',\n",
    "    'tofu', 'tortillas', 'tree nut', 'triple sec',\n",
    "    'tropical fruit', 'trout', 'turnip', 'vanilla',\n",
    "    'veal', 'venison', 'vermouth', 'vinegar',\n",
    "    'waffle', 'wasabi', 'watercress', 'watermelon',\n",
    "    'white wine', 'wine', 'yellow squash', 'yuca'\n",
    "]\n",
    "for value in actually_ingredients:\n",
    "    if value not in features:\n",
    "        if value not in df.columns:\n",
    "            print(f\"problem with: {value}\")\n",
    "        features.append(value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436650ff",
   "metadata": {},
   "source": [
    "## lets sort columns in our dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69d2e806",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[features]\n",
    "y=df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d268e6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20052, 322)\n",
      "(20052,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "onion         2238.0\n",
       "tomato        2140.0\n",
       "milk/cream    1995.0\n",
       "egg           1768.0\n",
       "herb          1681.0\n",
       "               ...  \n",
       "caviar           1.0\n",
       "waffle           1.0\n",
       "crêpe            1.0\n",
       "quiche           1.0\n",
       "sorbet           1.0\n",
       "Length: 322, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape) \n",
    "print(y.shape) \n",
    "\n",
    "X.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab26982",
   "metadata": {},
   "source": [
    "## Let's start tuning the hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a6c5f8",
   "metadata": {},
   "source": [
    "это чисто препроцессинг, то что я сделал выше мб оформлю его так же шобы в пайплайн запихать "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfa9dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd1f082",
   "metadata": {},
   "source": [
    "#### Train-test-validation split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d574bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_to_сat(y):\n",
    "    bins = [0, 2, 4, 6]\n",
    "    labels = ['bad', 'ok', 'good']\n",
    "    return pd.cut(y, bins=bins, labels=labels)\n",
    "\n",
    "class TrainValidationTest(BaseEstimator, TransformerMixin):\n",
    "        def __init__(self, test_size=0.2, random_state=21, stratified=True):\n",
    "            self.test_size = test_size\n",
    "            self.random_state = random_state\n",
    "            self.stratified = stratified\n",
    "        def split(self, X , y):\n",
    "            stratify = y if self.stratified else None\n",
    "            X_train, X_test, y_train, y_test =train_test_split(\n",
    "                X, y, test_size=self.test_size, random_state=self.random_state, stratify=stratify\n",
    "            )\n",
    "            X_train, X_valid, y_train, y_valid =train_test_split(\n",
    "                X_train, y_train, test_size=self.test_size/(1-self.test_size), random_state=self.random_state, stratify=stratify\n",
    "            )\n",
    "            return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5918900",
   "metadata": {},
   "source": [
    "#### Model selection class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979d1b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from itertools import product\n",
    "from sklearn.metrics import get_scorer\n",
    "def manual_grid_search(X_train, y_train, X_valid, y_valid, model_estimator,param_grid, cv, scoring='accuracy_score',  n_jobs=-1, error_score=np.nan):\n",
    "    res=[]\n",
    "    estimator=deepcopy(model_estimator)\n",
    "    total_combinations = np.prod([len(v) for v in param_grid.values()])\n",
    "    # get scorer for valid score\n",
    "    scorer = get_scorer(scoring)\n",
    "\n",
    "    for params in tqdm(list(product(*param_grid.values())), total=total_combinations, desc=\"GridSearch\"):\n",
    "\n",
    "        current_model = deepcopy(estimator)\n",
    "        current_model.set_params(**(dict(zip(param_grid.keys(), params))))\n",
    "        try:\n",
    "            score=cross_val_score(\n",
    "                current_model, X_train, y_train, cv=cv, scoring=scoring, n_jobs=n_jobs,error_score=error_score\n",
    "            )\n",
    "\n",
    "            current_model.fit(X_train, y_train)\n",
    "            valid_score=scorer(current_model, X_valid, y_valid)\n",
    "\n",
    "            res.append({\n",
    "                'train_score': score.mean(),\n",
    "                'valid_score': valid_score,\n",
    "                'params': dict(zip(param_grid.keys(), params))\n",
    "            })\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error with params {params}: {str(e)}\")\n",
    "            res.append({\n",
    "                **(dict(zip(param_grid.keys(), params))),\n",
    "                'train_score': 'Na',\n",
    "                'valid_score': 'Na'\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "    return pd.DataFrame(res).sort_values('valid_score', ascending=False)\n",
    "\n",
    "class ModelSelection:\n",
    "    def __init__ (self,estimators,estimators_name, grid_dict, scoring='accuracy_score'):\n",
    "        self.estimators=estimators\n",
    "        self.scoring=scoring\n",
    "        self.estimators_name=estimators_name\n",
    "        self.grid_dict=grid_dict\n",
    "        self.results=pd.DataFrame()\n",
    "        self.best_res=[]\n",
    "    def choose(self,X_train, y_train, X_valid, y_valid, cv=2):\n",
    "        \"\"\"\n",
    "        Method choose() takes X_train, y_train, X_valid, y_valid, optional cv, \n",
    "        and returns the name of the best model among all the models on the validation set\n",
    "        \"\"\"\n",
    "        for estimator in self.estimators:\n",
    "            model_name= self.estimators_name[self.estimators.index(estimator)]\n",
    "            search_res=manual_grid_search(X_train,y_train,X_valid, y_valid,estimator,self.grid_dict[model_name], cv=cv, scoring=self.scoring)\n",
    "            search_res['model']=model_name\n",
    "            best_params = search_res.head(1)['params'].item()\n",
    "            best_train_score = search_res.head(1)['train_score'].item()\n",
    "            best_valid_score = search_res.head(1)['valid_score'].item()\n",
    "            self.results=pd.concat([self.results, search_res], axis=0, ignore_index=True)\n",
    "            self.best_res.append({\n",
    "                'model': model_name,\n",
    "                'params': best_params,\n",
    "                'valid_score': best_valid_score,\n",
    "                'train_score': best_train_score\n",
    "            })\n",
    "            \n",
    "            print(f\"Best params for model{model_name}: {best_params}\")\n",
    "            print(f\"training accuracy: {best_train_score:.3f}\")\n",
    "            print(f\"Best on validation set accuracy score: {best_valid_score:.3f}\")\n",
    "        self.best_res=pd.DataFrame(self.best_res)\n",
    "        self.best_res.sort_values('valid_score', ascending=False,inplace=True)\n",
    "        best_model_name=self.best_res.head(1)['model'].item()\n",
    "        print(f\"\\nBest model: {best_model_name}\\nwith params: {self.best_res.head(1)['params'].item()}\\nand score: {self.best_res.head(1)['valid_score'].item()}\")\n",
    "        return self.results.sort_values('valid_score', ascending=False)\n",
    "    # def show_results(self):\n",
    "        # return self.results.groupby(by=\"model\").sort_values('valid_score', ascending=False)\n",
    "    def fit_score(self,X_comb,y_comb, X_test, y_test):\n",
    "        params=self.best_res.head(1)['params'].item()\n",
    "        model_name=self.best_res.head(1)['model'].item()\n",
    "        print(f'Taking model: {model_name} with params:{params}')\n",
    "        best_estimator=self.estimators[self.estimators_name.index(model_name)]\n",
    "        best_estimator.set_params(**(params))\n",
    "        best_estimator.fit(X_comb,y_comb)\n",
    "        scorer=get_scorer(self.scoring)\n",
    "        print(\"the final score is :\",(scorer(best_estimator,X_test,y_test)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3358a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_score(estimator, params, X_comb, y_comb, X_test, y_test, scoring='accuracy_score'):\n",
    "        estimator.set_params(**(params))\n",
    "        estimator.fit(X_comb,y_comb)\n",
    "        scorer=get_scorer(scoring)\n",
    "        print(\"the final score is :\",(scorer(estimator,X_test,y_test)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d895e4",
   "metadata": {},
   "source": [
    "# Regression serch params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ee08122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "estimators = [\n",
    "    LinearRegression(),\n",
    "    Ridge(),\n",
    "    Lasso(),\n",
    "    ElasticNet(),\n",
    "    RandomForestRegressor(random_state=21, n_jobs=-1),\n",
    "    GradientBoostingRegressor(random_state=21),\n",
    "    XGBRegressor(random_state=21, n_jobs=-1),\n",
    "    KernelRidge(),\n",
    "]\n",
    "\n",
    "estimators_name = [\n",
    "    'LinearRegression',\n",
    "    'Ridge',\n",
    "    'Lasso',\n",
    "    'ElasticNet',\n",
    "    'RandomForest',\n",
    "    'GradientBoosting',\n",
    "    'XGBoost',\n",
    "    'KernelRidge',\n",
    "]\n",
    "\n",
    "grid_dict = {\n",
    "    'LinearRegression': {\n",
    "        'fit_intercept': [True, False],\n",
    "        'positive': [False]\n",
    "    },\n",
    "    'Ridge': {\n",
    "        'alpha': [0.1, 1.0, 10.0],  \n",
    "        'solver': ['svd', 'cholesky', 'saga']  \n",
    "    },\n",
    "    'Lasso': {\n",
    "        'alpha': [0.01, 0.1, 1.0],  \n",
    "        'selection': ['cyclic']\n",
    "    },\n",
    "    'ElasticNet': {\n",
    "        'alpha': [0.01, 0.1, 1.0],\n",
    "        'l1_ratio': [0.3, 0.5, 0.7] \n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [50,100, 200], \n",
    "        'max_depth': [15,30, None],  \n",
    "        'min_samples_split': [2, 5,10],\n",
    "        'max_features': ['sqrt']\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 5],\n",
    "        'subsample': [0.8, 1.0]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [3, 6],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0]\n",
    "    },\n",
    "    'KernelRidge': {\n",
    "        'alpha': [0.1, 1.0, 10.0],\n",
    "        'kernel': ['rbf'],\n",
    "        'gamma': [None, 0.1]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d296a7",
   "metadata": {},
   "source": [
    "Regression grid search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccb8f92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df406be2ab8f4ff485c307454219e520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridSearch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for modelLinearRegression: {'fit_intercept': True, 'positive': False}\n",
      "training accuracy: -1.339\n",
      "Best on validation set accuracy score: -1.292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d08e682dde4996a475f46e30425709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridSearch:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for modelRidge: {'alpha': 10.0, 'solver': 'saga'}\n",
      "training accuracy: -1.320\n",
      "Best on validation set accuracy score: -1.282\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f0f60abefd4ec486704cd506ffdd4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridSearch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for modelLasso: {'alpha': 0.01, 'selection': 'cyclic'}\n",
      "training accuracy: -1.346\n",
      "Best on validation set accuracy score: -1.311\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4e301e0b8045b3aefabce3e55addd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridSearch:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for modelElasticNet: {'alpha': 0.01, 'l1_ratio': 0.3}\n",
      "training accuracy: -1.332\n",
      "Best on validation set accuracy score: -1.296\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d448a49d15754edd91dbfea36b2ea40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridSearch:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for modelRandomForest: {'n_estimators': 200, 'max_depth': 30, 'min_samples_split': 2, 'max_features': 'sqrt'}\n",
      "training accuracy: -1.317\n",
      "Best on validation set accuracy score: -1.271\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805f9dcf02304d75ae1841c8f5edb46b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridSearch:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for modelGradientBoosting: {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 5, 'subsample': 1.0}\n",
      "training accuracy: -1.332\n",
      "Best on validation set accuracy score: -1.276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308918358a02467f8c3ff9c21ce17a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridSearch:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for modelXGBoost: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample_bytree': 1.0}\n",
      "training accuracy: -1.330\n",
      "Best on validation set accuracy score: -1.273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1cbccd57d9498b9516fc17898d2d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GridSearch:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for modelKernelRidge: {'alpha': 1.0, 'kernel': 'rbf', 'gamma': 0.1}\n",
      "training accuracy: -1.313\n",
      "Best on validation set accuracy score: -1.275\n",
      "\n",
      "Best model: RandomForest\n",
      "with params: {'n_estimators': 200, 'max_depth': 30, 'min_samples_split': 2, 'max_features': 'sqrt'}\n",
      "and score: -1.271343441880819\n"
     ]
    }
   ],
   "source": [
    "scoring='neg_root_mean_squared_error'\n",
    "\n",
    "\n",
    "splitter = TrainValidationTest(stratified=False)\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = splitter.split(X, y)\n",
    "search_parametrs= ModelSelection(estimators,estimators_name, grid_dict, scoring)\n",
    "result_serching=search_parametrs.choose(X_train, y_train, X_valid, y_valid)\n",
    "X_comb=pd.concat([X_train, X_valid], axis=0, ignore_index=True)\n",
    "y_comb=pd.concat([y_train, y_valid], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99c4a19",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76044021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calc score on the best model\n",
      "Taking model: RandomForest with params:{'n_estimators': 200, 'max_depth': 30, 'min_samples_split': 2, 'max_features': 'sqrt'}\n",
      "the final score is : -1.2607774800247062\n"
     ]
    }
   ],
   "source": [
    "print(\"Calc score on the best model\")\n",
    "\n",
    "best_model_name = result_serching.iloc[0]['model']\n",
    "best_estimator = estimators[estimators_name.index(best_model_name)]\n",
    "params= result_serching.iloc[0]['params']\n",
    "print(f'Taking model: {best_model_name} with params:{params}')\n",
    "fit_score(best_estimator, params, X_comb,y_comb, X_test,y_test, scoring=scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1f80b7",
   "metadata": {},
   "source": [
    "let's analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54b0a238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>valid_score</th>\n",
       "      <th>params</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-1.317030</td>\n",
       "      <td>-1.271343</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 30, 'min_sa...</td>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1.317769</td>\n",
       "      <td>-1.271758</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 30, 'min_sa...</td>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-1.329763</td>\n",
       "      <td>-1.273091</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 6, 'learnin...</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-1.327541</td>\n",
       "      <td>-1.273299</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 6, 'learnin...</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-1.319519</td>\n",
       "      <td>-1.273352</td>\n",
       "      <td>{'n_estimators': 50, 'max_depth': 30, 'min_sam...</td>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_score  valid_score  \\\n",
       "23    -1.317030    -1.271343   \n",
       "24    -1.317769    -1.271758   \n",
       "66    -1.329763    -1.273091   \n",
       "67    -1.327541    -1.273299   \n",
       "25    -1.319519    -1.273352   \n",
       "\n",
       "                                               params         model  \n",
       "23  {'n_estimators': 200, 'max_depth': 30, 'min_sa...  RandomForest  \n",
       "24  {'n_estimators': 100, 'max_depth': 30, 'min_sa...  RandomForest  \n",
       "66  {'n_estimators': 200, 'max_depth': 6, 'learnin...       XGBoost  \n",
       "67  {'n_estimators': 200, 'max_depth': 6, 'learnin...       XGBoost  \n",
       "25  {'n_estimators': 50, 'max_depth': 30, 'min_sam...  RandomForest  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_serching.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1e96dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking model: XGBoost with params:{'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.1, 'subsample': 1.0, 'colsample_bytree': 1.0}\n",
      "the final score is : -1.2665302481544887\n"
     ]
    }
   ],
   "source": [
    "model_name = result_serching.iloc[2]['model']\n",
    "estimator = estimators[estimators_name.index(model_name)]\n",
    "params= result_serching.iloc[2]['params']\n",
    "print(f'Taking model: {model_name} with params:{params}')\n",
    "fit_score(estimator, params, X_comb, y_comb, X_test, y_test, scoring=scoring)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b909a7d",
   "metadata": {},
   "source": [
    "Lets take  RandomForest with params:{'n_estimators': 200, 'max_depth': 30, 'min_samples_split': 2, 'max_features': 'sqrt'}\n",
    "with the final score : -1.260777480024706"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2ad779e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=30, max_features=&#x27;sqrt&#x27;, n_estimators=200,\n",
       "                      n_jobs=-1, random_state=21)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>RandomForestRegressor(max_depth=30, max_features=&#x27;sqrt&#x27;, n_estimators=200,\n",
       "                      n_jobs=-1, random_state=21)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=30, max_features='sqrt', n_estimators=200,\n",
       "                      n_jobs=-1, random_state=21)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestRegressor_model=RandomForestRegressor(random_state=21, n_jobs=-1)\n",
    "RandomForestRegressor_model.set_params(**(result_serching.iloc[0]['params']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b0abaa",
   "metadata": {},
   "source": [
    "lets try do model that classifays on regression purpose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "968357d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m y_test_classification=rating_to_сat(y_test)\n\u001b[32m     24\u001b[39m y_pred=regresRegressionToClassifier.predict(X_test)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_classification\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/school21/DS_Bootcamp.Team01.ID_886525-Team_TL_shirledo.396ad497_d1b1_4d29-1/src/venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/school21/DS_Bootcamp.Team01.ID_886525-Team_TL_shirledo.396ad497_d1b1_4d29-1/src/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:227\u001b[39m, in \u001b[36maccuracy_score\u001b[39m\u001b[34m(y_true, y_pred, normalize, sample_weight)\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[32m    226\u001b[39m y_true, y_pred = attach_unique(y_true, y_pred)\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m y_type, y_true, y_pred = \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type.startswith(\u001b[33m\"\u001b[39m\u001b[33mmultilabel\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/school21/DS_Bootcamp.Team01.ID_886525-Team_TL_shirledo.396ad497_d1b1_4d29-1/src/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:99\u001b[39m, in \u001b[36m_check_targets\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n\u001b[32m     97\u001b[39m xp, _ = get_namespace(y_true, y_pred)\n\u001b[32m     98\u001b[39m check_consistent_length(y_true, y_pred)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m type_true = \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43my_true\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m type_pred = type_of_target(y_pred, input_name=\u001b[33m\"\u001b[39m\u001b[33my_pred\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    102\u001b[39m y_type = {type_true, type_pred}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/school21/DS_Bootcamp.Team01.ID_886525-Team_TL_shirledo.396ad497_d1b1_4d29-1/src/venv/lib/python3.12/site-packages/sklearn/utils/multiclass.py:423\u001b[39m, in \u001b[36mtype_of_target\u001b[39m\u001b[34m(y, input_name, raise_unknown)\u001b[39m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m issparse(first_row_or_val):\n\u001b[32m    422\u001b[39m     first_row_or_val = first_row_or_val.data\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcached_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m.shape[\u001b[32m0\u001b[39m] > \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y.ndim == \u001b[32m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(first_row_or_val) > \u001b[32m1\u001b[39m):\n\u001b[32m    424\u001b[39m     \u001b[38;5;66;03m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[39;00m\n\u001b[32m    425\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m + suffix\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/school21/DS_Bootcamp.Team01.ID_886525-Team_TL_shirledo.396ad497_d1b1_4d29-1/src/venv/lib/python3.12/site-packages/sklearn/utils/_unique.py:105\u001b[39m, in \u001b[36mcached_unique\u001b[39m\u001b[34m(xp, *ys)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_unique\u001b[39m(*ys, xp=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     82\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the unique values of ys.\u001b[39;00m\n\u001b[32m     83\u001b[39m \n\u001b[32m     84\u001b[39m \u001b[33;03m    Use the cached values from dtype.metadata if present.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m \u001b[33;03m        Unique values of ys.\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     res = \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_cached_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res) == \u001b[32m1\u001b[39m:\n\u001b[32m    107\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m res[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/school21/DS_Bootcamp.Team01.ID_886525-Team_TL_shirledo.396ad497_d1b1_4d29-1/src/venv/lib/python3.12/site-packages/sklearn/utils/_unique.py:105\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_unique\u001b[39m(*ys, xp=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     82\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the unique values of ys.\u001b[39;00m\n\u001b[32m     83\u001b[39m \n\u001b[32m     84\u001b[39m \u001b[33;03m    Use the cached values from dtype.metadata if present.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m \u001b[33;03m        Unique values of ys.\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     res = \u001b[38;5;28mtuple\u001b[39m(\u001b[43m_cached_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m ys)\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res) == \u001b[32m1\u001b[39m:\n\u001b[32m    107\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m res[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/school21/DS_Bootcamp.Team01.ID_886525-Team_TL_shirledo.396ad497_d1b1_4d29-1/src/venv/lib/python3.12/site-packages/sklearn/utils/_unique.py:78\u001b[39m, in \u001b[36m_cached_unique\u001b[39m\u001b[34m(y, xp)\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     77\u001b[39m xp, _ = get_namespace(y, xp=xp)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxp\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/school21/DS_Bootcamp.Team01.ID_886525-Team_TL_shirledo.396ad497_d1b1_4d29-1/src/venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:416\u001b[39m, in \u001b[36m_NumPyAPIWrapper.unique_values\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34munique_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/school21/DS_Bootcamp.Team01.ID_886525-Team_TL_shirledo.396ad497_d1b1_4d29-1/src/venv/lib/python3.12/site-packages/numpy/lib/_arraysetops_impl.py:286\u001b[39m, in \u001b[36munique\u001b[39m\u001b[34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[39m\n\u001b[32m    284\u001b[39m ar = np.asanyarray(ar)\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     ret = \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mar\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[32m    290\u001b[39m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/school21/DS_Bootcamp.Team01.ID_886525-Team_TL_shirledo.396ad497_d1b1_4d29-1/src/venv/lib/python3.12/site-packages/numpy/lib/_arraysetops_impl.py:353\u001b[39m, in \u001b[36m_unique1d\u001b[39m\u001b[34m(ar, return_index, return_inverse, return_counts, equal_nan, inverse_shape, axis)\u001b[39m\n\u001b[32m    351\u001b[39m     aux = ar[perm]\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     \u001b[43mar\u001b[49m\u001b[43m.\u001b[49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m     aux = ar\n\u001b[32m    355\u001b[39m mask = np.empty(aux.shape, dtype=np.bool)\n",
      "\u001b[31mTypeError\u001b[39m: '<' not supported between instances of 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "def rating_to_сat(y):\n",
    "    bins = [0, 2, 4, 6]\n",
    "    labels = ['bad', 'so-so', 'great']\n",
    "    return pd.cut(y, bins=bins, labels=labels)\n",
    "class RegressionToClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, regressor=None, bins=[0, 2, 4, 6], labels=['bad', 'so-so', 'great']):\n",
    "        self.regressor = regressor if regressor is not None else RandomForestRegressor()\n",
    "        self.bins = bins\n",
    "        self.labels = labels\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.regressor.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = self.regressor.predict(X)\n",
    "        return pd.cut(y_pred, bins=self.bins, labels=self.labels, include_lowest=True)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        raise NotImplementedError(\"predict_proba is not implemented for this classifier\")\n",
    "regresRegressionToClassifier = RegressionToClassifier(RandomForestRegressor_model)\n",
    "regresRegressionToClassifier.fit(X_comb,y_comb)\n",
    "y_test_classification=rating_to_сat(y_test)\n",
    "y_pred=regresRegressionToClassifier.predict(X_test)\n",
    "accuracy_score(y_test_classification,y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8012c45c",
   "metadata": {},
   "source": [
    "# classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f55eee0",
   "metadata": {},
   "source": [
    "## classes rounded to the closest integer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076307d0",
   "metadata": {},
   "source": [
    "prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227cf4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_int_class(y):\n",
    "    return y.round().astype(int)\n",
    "y_closest_int=closest_int_class(y)\n",
    "\n",
    "scoring='accuracy_score'\n",
    "\n",
    "\n",
    "splitter = TrainValidationTest(stratified=False)\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = splitter.split(X, y_closest_int)\n",
    "X_comb=pd.concat([X_train, X_valid], axis=0, ignore_index=True)\n",
    "y_comb=pd.concat([y_train, y_valid], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ce0295",
   "metadata": {},
   "source": [
    "diffrent models variants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c39e05e",
   "metadata": {},
   "source": [
    "search best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafe0ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_parametrs= ModelSelection(estimators,estimators_name, grid_dict, scoring)\n",
    "result_serching=search_parametrs.choose(X_train, y_train, X_valid, y_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "my_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
