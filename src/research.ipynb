{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cf177d6",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "f166f715",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='data/'\n",
    "api_key='ehlVSIKSMiugJZHlii3sU7OKCexe4MIlnYenGric'\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebdaf62",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "e04c1794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: 17736\n",
      "rating: 8\n",
      "calories: 1858\n",
      "protein: 282\n",
      "fat: 326\n",
      "sodium: 2434\n",
      "#cakeweek: 2\n",
      "#wasteless: 2\n",
      "22-minute meals: 2\n",
      "3-ingredient recipes: 2\n",
      "30 days of groceries: 2\n",
      "advance prep required: 2\n",
      "alabama: 2\n",
      "alaska: 2\n",
      "alcoholic: 2\n",
      "almond: 2\n",
      "amaretto: 2\n",
      "anchovy: 2\n",
      "anise: 2\n",
      "anniversary: 2\n",
      "anthony bourdain: 2\n",
      "aperitif: 2\n",
      "appetizer: 2\n",
      "apple: 2\n",
      "apple juice: 2\n",
      "apricot: 2\n",
      "arizona: 2\n",
      "artichoke: 2\n",
      "arugula: 2\n",
      "asian pear: 2\n",
      "asparagus: 2\n",
      "aspen: 2\n",
      "atlanta: 2\n",
      "australia: 2\n",
      "avocado: 2\n",
      "back to school: 2\n",
      "backyard bbq: 2\n",
      "bacon: 2\n",
      "bake: 2\n",
      "banana: 2\n",
      "barley: 2\n",
      "basil: 2\n",
      "bass: 2\n",
      "bastille day: 2\n",
      "bean: 2\n",
      "beef: 2\n",
      "beef rib: 2\n",
      "beef shank: 2\n",
      "beef tenderloin: 2\n",
      "beer: 2\n",
      "beet: 2\n",
      "bell pepper: 2\n",
      "berry: 2\n",
      "beverly hills: 2\n",
      "birthday: 2\n",
      "biscuit: 2\n",
      "bitters: 2\n",
      "blackberry: 2\n",
      "blender: 2\n",
      "blue cheese: 2\n",
      "blueberry: 2\n",
      "boil: 2\n",
      "bok choy: 2\n",
      "bon appétit: 2\n",
      "bon app��tit: 2\n",
      "boston: 2\n",
      "bourbon: 2\n",
      "braise: 2\n",
      "bran: 2\n",
      "brandy: 2\n",
      "bread: 2\n",
      "breadcrumbs: 2\n",
      "breakfast: 2\n",
      "brie: 2\n",
      "brine: 2\n",
      "brisket: 2\n",
      "broccoli: 2\n",
      "broccoli rabe: 2\n",
      "broil: 2\n",
      "brooklyn: 2\n",
      "brown rice: 2\n",
      "brownie: 2\n",
      "brunch: 2\n",
      "brussel sprout: 2\n",
      "buffalo: 2\n",
      "buffet: 2\n",
      "bulgaria: 2\n",
      "bulgur: 2\n",
      "burrito: 2\n",
      "butter: 2\n",
      "buttermilk: 2\n",
      "butternut squash: 2\n",
      "butterscotch/caramel: 2\n",
      "cabbage: 2\n",
      "cake: 2\n",
      "california: 2\n",
      "calvados: 2\n",
      "cambridge: 2\n",
      "campari: 2\n",
      "camping: 2\n",
      "canada: 2\n",
      "candy: 2\n",
      "candy thermometer: 2\n",
      "cantaloupe: 2\n",
      "capers: 2\n",
      "caraway: 2\n",
      "cardamom: 2\n",
      "carrot: 2\n",
      "cashew: 2\n",
      "casserole/gratin: 2\n",
      "cauliflower: 2\n",
      "caviar: 2\n",
      "celery: 2\n",
      "chambord: 2\n",
      "champagne: 2\n",
      "chard: 2\n",
      "chartreuse: 2\n",
      "cheddar: 2\n",
      "cheese: 2\n",
      "cherry: 2\n",
      "chestnut: 2\n",
      "chicago: 2\n",
      "chicken: 2\n",
      "chickpea: 2\n",
      "chile: 2\n",
      "chile pepper: 2\n",
      "chili: 2\n",
      "chill: 2\n",
      "chive: 2\n",
      "chocolate: 2\n",
      "christmas: 2\n",
      "christmas eve: 2\n",
      "cilantro: 2\n",
      "cinco de mayo: 2\n",
      "cinnamon: 2\n",
      "citrus: 2\n",
      "clam: 2\n",
      "clove: 2\n",
      "cobbler/crumble: 2\n",
      "cocktail: 2\n",
      "cocktail party: 2\n",
      "coconut: 2\n",
      "cod: 2\n",
      "coffee: 2\n",
      "coffee grinder: 2\n",
      "cognac/armagnac: 2\n",
      "collard greens: 2\n",
      "colorado: 2\n",
      "columbus: 2\n",
      "condiment: 2\n",
      "condiment/spread: 2\n",
      "connecticut: 2\n",
      "cook like a diner: 2\n",
      "cookbook critic: 2\n",
      "cookie: 2\n",
      "cookies: 2\n",
      "coriander: 2\n",
      "corn: 2\n",
      "cornmeal: 2\n",
      "costa mesa: 2\n",
      "cottage cheese: 2\n",
      "couscous: 2\n",
      "crab: 2\n",
      "cranberry: 2\n",
      "cranberry sauce: 2\n",
      "cream cheese: 2\n",
      "créme de cacao: 2\n",
      "crêpe: 2\n",
      "cr��me de cacao: 2\n",
      "cuba: 2\n",
      "cucumber: 2\n",
      "cumin: 2\n",
      "cupcake: 2\n",
      "currant: 2\n",
      "curry: 2\n",
      "custard: 2\n",
      "dairy: 2\n",
      "dairy free: 2\n",
      "dallas: 2\n",
      "date: 2\n",
      "deep-fry: 2\n",
      "denver: 2\n",
      "dessert: 2\n",
      "digestif: 2\n",
      "dill: 2\n",
      "dinner: 2\n",
      "dip: 2\n",
      "diwali: 2\n",
      "dominican republic: 2\n",
      "dorie greenspan: 2\n",
      "double boiler: 2\n",
      "dried fruit: 2\n",
      "drink: 2\n",
      "drinks: 2\n",
      "duck: 2\n",
      "easter: 2\n",
      "eau de vie: 2\n",
      "edible gift: 2\n",
      "egg: 2\n",
      "egg nog: 2\n",
      "eggplant: 2\n",
      "egypt: 2\n",
      "emeril lagasse: 2\n",
      "endive: 2\n",
      "engagement party: 2\n",
      "england: 2\n",
      "entertaining: 2\n",
      "epi + ushg: 2\n",
      "epi loves the microwave: 2\n",
      "escarole: 2\n",
      "fall: 2\n",
      "family reunion: 2\n",
      "fat free: 2\n",
      "father's day: 2\n",
      "fennel: 2\n",
      "feta: 2\n",
      "fig: 2\n",
      "fish: 2\n",
      "flaming hot summer: 2\n",
      "flat bread: 2\n",
      "florida: 2\n",
      "fontina: 2\n",
      "food processor: 2\n",
      "fortified wine: 2\n",
      "fourth of july: 2\n",
      "france: 2\n",
      "frangelico: 2\n",
      "frankenrecipe: 2\n",
      "freeze/chill: 2\n",
      "freezer food: 2\n",
      "friendsgiving: 2\n",
      "frittata: 2\n",
      "fritter: 2\n",
      "frozen dessert: 2\n",
      "fruit: 2\n",
      "fruit juice: 2\n",
      "fry: 2\n",
      "game: 2\n",
      "garlic: 2\n",
      "georgia: 2\n",
      "germany: 2\n",
      "gin: 2\n",
      "ginger: 2\n",
      "goat cheese: 2\n",
      "goose: 2\n",
      "gouda: 2\n",
      "gourmet: 2\n",
      "graduation: 2\n",
      "grains: 2\n",
      "grand marnier: 2\n",
      "granola: 2\n",
      "grape: 2\n",
      "grapefruit: 2\n",
      "grappa: 2\n",
      "green bean: 2\n",
      "green onion/scallion: 2\n",
      "grill: 2\n",
      "grill/barbecue: 2\n",
      "ground beef: 2\n",
      "ground lamb: 2\n",
      "guam: 2\n",
      "guava: 2\n",
      "haiti: 2\n",
      "halibut: 2\n",
      "halloween: 2\n",
      "ham: 2\n",
      "hamburger: 2\n",
      "hanukkah: 2\n",
      "harpercollins: 2\n",
      "hawaii: 2\n",
      "hazelnut: 2\n",
      "healdsburg: 2\n",
      "healthy: 2\n",
      "herb: 2\n",
      "high fiber: 2\n",
      "hollywood: 2\n",
      "hominy/cornmeal/masa: 2\n",
      "honey: 2\n",
      "honeydew: 2\n",
      "hors d'oeuvre: 2\n",
      "horseradish: 2\n",
      "hot drink: 2\n",
      "hot pepper: 2\n",
      "house & garden: 2\n",
      "house cocktail: 2\n",
      "houston: 2\n",
      "hummus: 2\n",
      "ice cream: 2\n",
      "ice cream machine: 2\n",
      "iced coffee: 2\n",
      "iced tea: 2\n",
      "idaho: 2\n",
      "illinois: 2\n",
      "indiana: 2\n",
      "iowa: 2\n",
      "ireland: 2\n",
      "israel: 2\n",
      "italy: 2\n",
      "jalapeño: 2\n",
      "jam or jelly: 2\n",
      "jamaica: 2\n",
      "japan: 2\n",
      "jerusalem artichoke: 2\n",
      "juicer: 2\n",
      "jícama: 2\n",
      "kahlúa: 2\n",
      "kale: 2\n",
      "kansas: 2\n",
      "kansas city: 2\n",
      "kentucky: 2\n",
      "kentucky derby: 2\n",
      "kid-friendly: 2\n",
      "kidney friendly: 2\n",
      "kirsch: 2\n",
      "kitchen olympics: 2\n",
      "kiwi: 2\n",
      "kosher: 2\n",
      "kosher for passover: 2\n",
      "kumquat: 2\n",
      "kwanzaa: 2\n",
      "labor day: 2\n",
      "lamb: 2\n",
      "lamb chop: 2\n",
      "lamb shank: 2\n",
      "lancaster: 2\n",
      "las vegas: 2\n",
      "lasagna: 2\n",
      "leafy green: 2\n",
      "leek: 2\n",
      "legume: 2\n",
      "lemon: 2\n",
      "lemon juice: 2\n",
      "lemongrass: 2\n",
      "lentil: 2\n",
      "lettuce: 2\n",
      "lima bean: 2\n",
      "lime: 2\n",
      "lime juice: 2\n",
      "lingonberry: 2\n",
      "liqueur: 2\n",
      "lobster: 2\n",
      "london: 2\n",
      "long beach: 2\n",
      "los angeles: 2\n",
      "louisiana: 2\n",
      "louisville: 2\n",
      "low cal: 2\n",
      "low carb: 2\n",
      "low cholesterol: 2\n",
      "low fat: 2\n",
      "low sodium: 2\n",
      "low sugar: 2\n",
      "low/no sugar: 2\n",
      "lunar new year: 2\n",
      "lunch: 2\n",
      "lychee: 2\n",
      "macadamia nut: 2\n",
      "macaroni and cheese: 2\n",
      "maine: 2\n",
      "mandoline: 2\n",
      "mango: 2\n",
      "maple syrup: 2\n",
      "mardi gras: 2\n",
      "margarita: 2\n",
      "marinade: 2\n",
      "marinate: 2\n",
      "marsala: 2\n",
      "marscarpone: 2\n",
      "marshmallow: 2\n",
      "martini: 2\n",
      "maryland: 2\n",
      "massachusetts: 2\n",
      "mayonnaise: 2\n",
      "meat: 2\n",
      "meatball: 2\n",
      "meatloaf: 2\n",
      "melon: 2\n",
      "mexico: 2\n",
      "mezcal: 2\n",
      "miami: 2\n",
      "michigan: 2\n",
      "microwave: 2\n",
      "midori: 2\n",
      "milk/cream: 2\n",
      "minneapolis: 2\n",
      "minnesota: 2\n",
      "mint: 2\n",
      "mississippi: 2\n",
      "missouri: 2\n",
      "mixer: 2\n",
      "molasses: 2\n",
      "monterey jack: 2\n",
      "mortar and pestle: 2\n",
      "mother's day: 2\n",
      "mozzarella: 2\n",
      "muffin: 2\n",
      "mushroom: 2\n",
      "mussel: 2\n",
      "mustard: 2\n",
      "mustard greens: 2\n",
      "nancy silverton: 2\n",
      "nebraska: 2\n",
      "nectarine: 2\n",
      "new hampshire: 2\n",
      "new jersey: 2\n",
      "new mexico: 2\n",
      "new orleans: 2\n",
      "new year's day: 2\n",
      "new year's eve: 2\n",
      "new york: 2\n",
      "no meat, no problem: 2\n",
      "no sugar added: 2\n",
      "no-cook: 2\n",
      "non-alcoholic: 2\n",
      "noodle: 2\n",
      "north carolina: 2\n",
      "nut: 2\n",
      "nutmeg: 2\n",
      "oat: 2\n",
      "oatmeal: 2\n",
      "octopus: 2\n",
      "ohio: 2\n",
      "oklahoma: 2\n",
      "okra: 2\n",
      "oktoberfest: 2\n",
      "olive: 2\n",
      "omelet: 2\n",
      "one-pot meal: 2\n",
      "onion: 2\n",
      "orange: 2\n",
      "orange juice: 2\n",
      "oregano: 2\n",
      "oregon: 2\n",
      "organic: 2\n",
      "orzo: 2\n",
      "oscars: 2\n",
      "oyster: 2\n",
      "pacific palisades: 2\n",
      "paleo: 2\n",
      "pan-fry: 2\n",
      "pancake: 2\n",
      "papaya: 2\n",
      "paprika: 2\n",
      "parade: 2\n",
      "paris: 2\n",
      "parmesan: 2\n",
      "parsley: 2\n",
      "parsnip: 2\n",
      "party: 2\n",
      "pasadena: 2\n",
      "passion fruit: 2\n",
      "passover: 2\n",
      "pasta: 2\n",
      "pasta maker: 2\n",
      "pastry: 2\n",
      "pea: 2\n",
      "peach: 2\n",
      "peanut: 2\n",
      "peanut butter: 2\n",
      "peanut free: 2\n",
      "pear: 2\n",
      "pecan: 2\n",
      "pennsylvania: 2\n",
      "pepper: 2\n",
      "pernod: 2\n",
      "persian new year: 2\n",
      "persimmon: 2\n",
      "peru: 2\n",
      "pescatarian: 2\n",
      "philippines: 2\n",
      "phyllo/puff pastry dough: 2\n",
      "pickles: 2\n",
      "picnic: 2\n",
      "pie: 2\n",
      "pine nut: 2\n",
      "pineapple: 2\n",
      "pistachio: 2\n",
      "pittsburgh: 2\n",
      "pizza: 2\n",
      "plantain: 2\n",
      "plum: 2\n",
      "poach: 2\n",
      "poblano: 2\n",
      "poker/game night: 2\n",
      "pomegranate: 2\n",
      "pomegranate juice: 2\n",
      "poppy: 2\n",
      "pork: 2\n",
      "pork chop: 2\n",
      "pork rib: 2\n",
      "pork tenderloin: 2\n",
      "port: 2\n",
      "portland: 2\n",
      "pot pie: 2\n",
      "potato: 2\n",
      "potato salad: 2\n",
      "potluck: 2\n",
      "poultry: 2\n",
      "poultry sausage: 2\n",
      "pressure cooker: 2\n",
      "prosciutto: 2\n",
      "providence: 2\n",
      "prune: 2\n",
      "pumpkin: 2\n",
      "punch: 2\n",
      "purim: 2\n",
      "quail: 2\n",
      "quiche: 2\n",
      "quick & easy: 2\n",
      "quick and healthy: 2\n",
      "quince: 2\n",
      "quinoa: 2\n",
      "rabbit: 2\n",
      "rack of lamb: 2\n",
      "radicchio: 2\n",
      "radish: 2\n",
      "raisin: 2\n",
      "ramadan: 2\n",
      "ramekin: 2\n",
      "raspberry: 2\n",
      "raw: 2\n",
      "red wine: 2\n",
      "rhode island: 2\n",
      "rhubarb: 2\n",
      "rice: 2\n",
      "ricotta: 2\n",
      "roast: 2\n",
      "root vegetable: 2\n",
      "rosemary: 2\n",
      "rosh hashanah/yom kippur: 2\n",
      "rosé: 2\n",
      "rub: 2\n",
      "rum: 2\n",
      "rutabaga: 2\n",
      "rye: 2\n",
      "saffron: 2\n",
      "sage: 2\n",
      "sake: 2\n",
      "salad: 2\n",
      "salad dressing: 2\n",
      "salmon: 2\n",
      "salsa: 2\n",
      "san francisco: 2\n",
      "sandwich: 2\n",
      "sandwich theory: 2\n",
      "sangria: 2\n",
      "santa monica: 2\n",
      "sardine: 2\n",
      "sauce: 2\n",
      "sausage: 2\n",
      "sauté: 2\n",
      "scallop: 2\n",
      "scotch: 2\n",
      "seafood: 2\n",
      "seattle: 2\n",
      "seed: 2\n",
      "self: 2\n",
      "semolina: 2\n",
      "sesame: 2\n",
      "sesame oil: 2\n",
      "shallot: 2\n",
      "shavuot: 2\n",
      "shellfish: 2\n",
      "sherry: 2\n",
      "shower: 2\n",
      "shrimp: 2\n",
      "side: 2\n",
      "simmer: 2\n",
      "skewer: 2\n",
      "slow cooker: 2\n",
      "smoker: 2\n",
      "smoothie: 2\n",
      "snapper: 2\n",
      "sorbet: 2\n",
      "soufflé/meringue: 2\n",
      "soup/stew: 2\n",
      "sour cream: 2\n",
      "sourdough: 2\n",
      "south carolina: 2\n",
      "soy: 2\n",
      "soy free: 2\n",
      "soy sauce: 2\n",
      "spain: 2\n",
      "sparkling wine: 2\n",
      "spice: 2\n",
      "spinach: 2\n",
      "spirit: 2\n",
      "spring: 2\n",
      "spritzer: 2\n",
      "squash: 2\n",
      "squid: 2\n",
      "st. louis: 2\n",
      "st. patrick's day: 2\n",
      "steak: 2\n",
      "steam: 2\n",
      "stew: 2\n",
      "stir-fry: 2\n",
      "stock: 2\n",
      "strawberry: 2\n",
      "stuffing/dressing: 2\n",
      "sugar conscious: 2\n",
      "sugar snap pea: 2\n",
      "sukkot: 2\n",
      "summer: 2\n",
      "super bowl: 2\n",
      "suzanne goin: 2\n",
      "sweet potato/yam: 2\n",
      "swiss cheese: 2\n",
      "switzerland: 2\n",
      "swordfish: 2\n",
      "taco: 2\n",
      "tailgating: 2\n",
      "tamarind: 2\n",
      "tangerine: 2\n",
      "tapioca: 2\n",
      "tarragon: 2\n",
      "tart: 2\n",
      "tea: 2\n",
      "tennessee: 2\n",
      "tequila: 2\n",
      "tested & improved: 2\n",
      "texas: 2\n",
      "thanksgiving: 2\n",
      "thyme: 2\n",
      "tilapia: 2\n",
      "tofu: 2\n",
      "tomatillo: 2\n",
      "tomato: 2\n",
      "tortillas: 2\n",
      "tree nut: 2\n",
      "tree nut free: 2\n",
      "triple sec: 2\n",
      "tropical fruit: 2\n",
      "trout: 2\n",
      "tuna: 2\n",
      "turnip: 2\n",
      "utah: 2\n",
      "valentine's day: 2\n",
      "vanilla: 2\n",
      "veal: 2\n",
      "vegan: 2\n",
      "vegetable: 2\n",
      "vegetarian: 2\n",
      "venison: 2\n",
      "vermont: 2\n",
      "vermouth: 2\n",
      "vinegar: 2\n",
      "virginia: 2\n",
      "vodka: 2\n",
      "waffle: 2\n",
      "walnut: 2\n",
      "wasabi: 2\n",
      "washington: 2\n",
      "washington, d.c.: 2\n",
      "watercress: 2\n",
      "watermelon: 2\n",
      "wedding: 2\n",
      "weelicious: 2\n",
      "west virginia: 2\n",
      "westwood: 2\n",
      "wheat/gluten-free: 2\n",
      "whiskey: 2\n",
      "white wine: 2\n",
      "whole wheat: 2\n",
      "wild rice: 2\n",
      "windsor: 2\n",
      "wine: 2\n",
      "winter: 2\n",
      "wisconsin: 2\n",
      "wok: 2\n",
      "yellow squash: 2\n",
      "yogurt: 2\n",
      "yonkers: 2\n",
      "yuca: 2\n",
      "zucchini: 2\n",
      "cookbooks: 2\n",
      "leftovers: 2\n",
      "snack: 2\n",
      "snack week: 2\n",
      "turkey: 2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{data_path}epi_r.csv\")\n",
    "\n",
    "for name, count in df.nunique().items():\n",
    "    print(f\"{name}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860a3825",
   "metadata": {},
   "source": [
    "The dataset have target feature:\n",
    "```rating```.\n",
    "\n",
    "There is also features: ```title, calories, protein, fat, sodium```\n",
    "\n",
    "\n",
    "\n",
    "Dataset have 2 categorical features after the One-Hot Encoding conversion.\n",
    "\n",
    "first categorical feature is:\n",
    "\n",
    "Ingredients: ```almond, anchovy, apple, avocado, bacon```\n",
    "\n",
    "second categorical feature is tags\n",
    "\n",
    "The tags may contain:\n",
    "* Recipe characteristics: ```#cakeweek, #wasteless, 22-minute meals, 3-ingredient recipes...```\n",
    "\n",
    "* Geographical affiliation: ```alabama, arizona, boston, france, italy...```\n",
    "\n",
    "* Dietary restrictions and features: ```dairy free, gluten free, vegan...```\n",
    "\n",
    "* Cooking methods: ```bake, boil, grill, slow cooker...```\n",
    "\n",
    "* Holidays and events: ```christmas, halloween, valentine's day...```\n",
    "\n",
    "* Machinery and tools: ```blender, food processor, pressure cooker, microwave...```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136e1fab",
   "metadata": {},
   "source": [
    "кароче грубо говоря нужно с помощью апи проверять является ли признак ингредиентом, если да оставляем его в выборке "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87463dd6",
   "metadata": {},
   "source": [
    "for future needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "2ecb71ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nutrients_list = [\n",
    "    # Основные макронутриенты \n",
    "    \"Total lipid (fat)\",\n",
    "    \"Fatty acids, total saturated\",\n",
    "    \"Fatty acids, total monounsaturated\",\n",
    "    \"Fatty acids, total polyunsaturated\",\n",
    "    \"Fatty acids, total trans\",\n",
    "    \"Cholesterol\",\n",
    "    \"Carbohydrate, by difference\",\n",
    "    \"Sodium, Na\", \n",
    "    \"Fiber, total dietary\",\n",
    "    \"Protein\",\n",
    "    \"Sugars, Total\",  \n",
    "    \"Energy\", \n",
    "    \"Vitamin A, RAE\",  \n",
    "    \"Vitamin C, total ascorbic acid\", \n",
    "    \"Vitamin D (D2 + D3)\",\n",
    "    \"Vitamin E (alpha-tocopherol)\",\n",
    "    \"Vitamin K (phylloquinone)\",\n",
    "    \"Thiamin\",\n",
    "    \"Riboflavin\",\n",
    "    \"Niacin\",\n",
    "    \"Vitamin B-6\",\n",
    "    \"Folate, total\",\n",
    "    \"Vitamin B-12\",\n",
    "    \n",
    "    # Минералы\n",
    "    \"Calcium, Ca\",\n",
    "    \"Iron, Fe\",\n",
    "    \"Phosphorus, P\",\n",
    "    \"Magnesium, Mg\",\n",
    "    \"Zinc, Zn\",\n",
    "    \"Copper, Cu\",\n",
    "    \"Manganese, Mn\",\n",
    "    \"Selenium, Se\",\n",
    "    \"Potassium, K\",\n",
    "    \n",
    "    # Специфичные компоненты \n",
    "    \"Ash\",\n",
    "    \"Nitrogen\",\n",
    "    \"Water\",\n",
    "    \n",
    "    # Разные формы сахаров\n",
    "    \"Fructose\",\n",
    "    \"Glucose\",\n",
    "    \"Sucrose\",\n",
    "    \"Galactose\"\n",
    "]\n",
    "    \n",
    "len(nutrients_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062b7635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "def load_nutrients_cache():\n",
    "    try:\n",
    "        with open(f\"{data_path}nutrients_cache.json\", 'r', encoding='utf-8') as f:\n",
    "            try:\n",
    "                return json.load(f)\n",
    "            except:\n",
    "                return {}\n",
    "    except:\n",
    "        return {}\n",
    "def save_to_cache(ingredient, ingredient_info,cache):\n",
    "    nutrient_df=pd.json_normalize(ingredient_info)[['nutrientName','unitName','value']]\n",
    "    nutrient_dict=nutrient_df[nutrient_df['nutrientName'].isin(nutrients_list)].to_dict()\n",
    "    cache[ingredient]=nutrient_dict\n",
    "    with open(f\"{data_path}nutrients_cache.json\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(cache, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "def get_nutrients_info(ingredient):\n",
    "    ingredient_info=None\n",
    "    params = {\n",
    "        \"query\": f'\"{ingredient}\"',\n",
    "        \"api_key\": api_key,\n",
    "        \"dataType\": [\"Foundation\"]  \n",
    "    }\n",
    "    cache=load_nutrients_cache()\n",
    "    if ingredient in cache:\n",
    "        print(ingredient, \"ok\")\n",
    "        return cache[ingredient]\n",
    "    response = requests.get('https://api.nal.usda.gov/fdc/v1/foods/search', params=params)\n",
    "    if response.status_code == 200:\n",
    "        ingredient_info = response.json().get('foods')\n",
    "        if ingredient_info and ingredient_info[0].get('score') < 200:\n",
    "            ingredient_info=None\n",
    "        if ingredient_info:\n",
    "            ingredient_info=ingredient_info[0].get('foodNutrients')\n",
    "            save_to_cache(ingredient, ingredient_info, cache)\n",
    "    return ingredient_info\n",
    "def is_ingredient(ingredient):\n",
    "    data=get_nutrients_info(ingredient)\n",
    "\n",
    "    return True if data else False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73a0e1b",
   "metadata": {},
   "source": [
    "## 2 lets sort columns in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "87648796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fat', 'sodium', 'almond', 'apple', 'apple juice', 'apricot', 'arugula', 'asparagus', 'avocado', 'bacon', 'banana', 'barley', 'bean', 'beef', 'beef tenderloin', 'beet', 'blackberry', 'blueberry', 'boil', 'bok choy', 'braise', 'bran', 'bread', 'breakfast', 'broccoli', 'broil', 'brussel sprout', 'bulgur', 'butter', 'buttermilk', 'cabbage', 'cantaloupe', 'carrot', 'cashew', 'cauliflower', 'celery', 'cheddar', 'cherry', 'chestnut', 'chicken', 'chickpea', 'coconut', 'cod', 'cookie', 'cookies', 'corn', 'cottage cheese', 'crab', 'cranberry', 'cream cheese', 'cucumber', 'dill', 'egg', 'eggplant', 'fat free', 'feta', 'fig', 'fish', 'garlic', 'grains', 'grape', 'grapefruit', 'green onion/scallion', 'ham', 'hazelnut', 'honeydew', 'hummus', 'kale', 'kiwi', 'kosher', 'lamb', 'leek', 'lentil', 'lettuce', 'low fat', 'macadamia nut', 'mango', 'meat', 'melon', 'monterey jack', 'mozzarella', 'mushroom', 'mustard', 'nectarine', 'no sugar added', 'no-cook', 'nut', 'oat', 'oatmeal', 'olive', 'onion', 'orange', 'orange juice', 'oyster', 'parmesan', 'pasta', 'pastry', 'pea', 'peach', 'peanut', 'peanut butter', 'pear', 'pecan', 'pepper', 'pickles', 'pie', 'pine nut', 'pineapple', 'pistachio', 'plantain', 'plum', 'pomegranate', 'pork', 'pork chop', 'potato', 'prune', 'pumpkin', 'quinoa', 'raisin', 'raspberry', 'raw', 'rice', 'ricotta', 'rutabaga', 'rye', 'salmon', 'salsa', 'sausage', 'seed', 'semolina', 'sesame', 'shallot', 'shrimp', 'soy', 'spinach', 'squash', 'steak', 'strawberry', 'summer', 'tart', 'tilapia', 'tomatillo', 'tomato', 'tuna', 'walnut', 'whole wheat', 'wild rice', 'winter', 'yogurt', 'zucchini', 'turkey']\n"
     ]
    }
   ],
   "source": [
    "features =[]\n",
    "for column in df.columns:\n",
    "    if is_ingredient(column):\n",
    "        features.append(column)\n",
    "print (features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2cf688",
   "metadata": {},
   "source": [
    "## Now we get the cloumns for X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "2340ce45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['almond', 'apple', 'apple juice', 'apricot', 'arugula', 'asparagus', 'avocado', 'bacon', 'banana', 'barley', 'bean', 'beef', 'beef tenderloin', 'beet', 'blackberry', 'blueberry', 'bok choy', 'bran', 'bread', 'broccoli', 'brussel sprout', 'bulgur', 'butter', 'buttermilk', 'cabbage', 'cantaloupe', 'carrot', 'cashew', 'cauliflower', 'celery', 'cheddar', 'cherry', 'chestnut', 'chicken', 'chickpea', 'coconut', 'cod', 'corn', 'cottage cheese', 'crab', 'cranberry', 'cream cheese', 'cucumber', 'dill', 'egg', 'eggplant', 'feta', 'fig', 'fish', 'garlic', 'grains', 'grape', 'grapefruit', 'green onion/scallion', 'ham', 'hazelnut', 'honeydew', 'hummus', 'kale', 'kiwi', 'lamb', 'leek', 'lentil', 'lettuce', 'macadamia nut', 'mango', 'meat', 'melon', 'monterey jack', 'mozzarella', 'mushroom', 'mustard', 'nectarine', 'nut', 'oat', 'oatmeal', 'olive', 'onion', 'orange', 'orange juice', 'oyster', 'parmesan', 'pasta', 'pea', 'peach', 'peanut', 'peanut butter', 'pear', 'pecan', 'pepper', 'pickles', 'pine nut', 'pineapple', 'pistachio', 'plantain', 'plum', 'pomegranate', 'pork', 'pork chop', 'potato', 'prune', 'pumpkin', 'quinoa', 'raisin', 'raspberry', 'rice', 'ricotta', 'rutabaga', 'rye', 'salmon', 'salsa', 'sausage', 'seed', 'semolina', 'sesame', 'shallot', 'shrimp', 'soy', 'spinach', 'squash', 'steak', 'strawberry', 'tilapia', 'tomatillo', 'tomato', 'tuna', 'walnut', 'whole wheat', 'wild rice', 'yogurt', 'zucchini', 'turkey']\n"
     ]
    }
   ],
   "source": [
    "non_ingredients = [\n",
    "    'fat',\n",
    "    'sodium',\n",
    "    \"boil\",        \n",
    "    \"braise\",       \n",
    "    \"breakfast\",   \n",
    "    \"broil\",        \n",
    "    \"cookie\",       \n",
    "    \"cookies\",      \n",
    "    \"fat free\",     \n",
    "    \"kosher\",        \n",
    "    \"low fat\",      \n",
    "    \"no sugar added\", \n",
    "    \"no-cook\",   \n",
    "    \"pastry\",     \n",
    "    \"pie\",    \n",
    "    \"raw\",          \n",
    "    \"summer\",      \n",
    "    \"tart\",       \n",
    "    \"winter\",       \n",
    "]\n",
    "for value in non_ingredients:\n",
    "    if value in features:\n",
    "        features.remove(value)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "69d2e806",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[features]\n",
    "y=df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "d268e6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20052, 132)\n",
      "(20052,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "onion          2238.0\n",
       "tomato         2140.0\n",
       "egg            1768.0\n",
       "garlic         1643.0\n",
       "chicken        1344.0\n",
       "                ...  \n",
       "grains            9.0\n",
       "apple juice       6.0\n",
       "salsa             6.0\n",
       "bran              3.0\n",
       "hummus            2.0\n",
       "Length: 132, dtype: float64"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape) \n",
    "print(y.shape) \n",
    "\n",
    "X.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567af7fd",
   "metadata": {},
   "source": [
    "### now not edited funcs for grid searching \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a6c5f8",
   "metadata": {},
   "source": [
    "это чисто препроцессинг, то что я сделал выше мб оформлю его так же шобы в пайплайн запихать "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "cfa9dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c052536c",
   "metadata": {},
   "source": [
    "#### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "5d574bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.dropna(subset=['timestamp'])\n",
    "        X['dayofweek']=X['timestamp'].dt.dayofweek\n",
    "        X['hour']=X['timestamp'].dt.hour\n",
    "        return X.drop('timestamp',axis=1)\n",
    "class MyOneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, target_name,handle_unknown='ignore',sparse_output=False):\n",
    "        self.target_name=target_name\n",
    "        self.encoder=OneHotEncoder(handle_unknown=handle_unknown,sparse_output=sparse_output)\n",
    "        self.categorical_features=None\n",
    "    def fit(self, X,y=None):\n",
    "        self.categorical_features=X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        if self.target_name in self.categorical_features:\n",
    "            self.categorical_features.remove(self.target_name)\n",
    "        if self.categorical_features:\n",
    "            self.encoder.fit(X[self.categorical_features])\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        X_transform=X.copy()\n",
    "        y=X_transform.pop(self.target_name)\n",
    "        encoded_data=pd.DataFrame(self.encoder.transform(X_transform[self.categorical_features]), columns=self.encoder.get_feature_names_out(self.categorical_features),index=X_transform.index)\n",
    "        return pd.concat([X_transform.drop(self.categorical_features,axis=1),encoded_data], axis=1), y\n",
    "    \n",
    "class TrainValidationTest(BaseEstimator, TransformerMixin):\n",
    "        def __init__(self, test_size=0.2, random_state=21, stratified=True):\n",
    "            self.test_size = test_size\n",
    "            self.random_state = random_state\n",
    "            self.stratified = stratified\n",
    "        def split(self, X , y):\n",
    "            stratify = y if self.stratified else None\n",
    "            X_train, X_test, y_train, y_test =train_test_split(\n",
    "                X, y, test_size=self.test_size, random_state=self.random_state, stratify=stratify\n",
    "            )\n",
    "            X_train, X_valid, y_train, y_valid =train_test_split(\n",
    "                X, y, test_size=self.test_size/(1-self.test_size), random_state=self.random_state, stratify=stratify\n",
    "            )\n",
    "            return X_train, X_valid, X_test, y_train, y_valid, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5918900",
   "metadata": {},
   "source": [
    "#### Model selection pipeline(need to edit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "0edc3496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from itertools import product\n",
    "from sklearn.metrics import get_scorer\n",
    "def manual_grid_search(X_train, y_train, gs_instance, X_valid, y_valid,  n_jobs=-1, error_score=np.nan):\n",
    "    res=[]\n",
    "    estimator=deepcopy(gs_instance.estimator)\n",
    "    param_grid=gs_instance.param_grid[0]\n",
    "    scoring=gs_instance.scoring\n",
    "    cv=gs_instance.cv\n",
    "    total_combinations = np.prod([len(v) for v in param_grid.values()])\n",
    "    # get scorer for valid score\n",
    "    scorer = get_scorer(scoring)\n",
    "    for params in tqdm(list(product(*param_grid.values())), total=total_combinations, desc=\"GridSearch\"):\n",
    "        current_model = deepcopy(estimator)\n",
    "        current_model.set_params(**(dict(zip(param_grid.keys(), params))))\n",
    "        try:\n",
    "\n",
    "            score=cross_val_score(\n",
    "                current_model, X_train, y_train, cv=cv, scoring=scoring, n_jobs=n_jobs,error_score=error_score\n",
    "            )\n",
    "\n",
    "            current_model.fit(X_train, y_train)\n",
    "            valid_score=scorer(current_model, X_valid, y_valid)\n",
    "\n",
    "            res.append({\n",
    "                **(dict(zip(param_grid.keys(), params))),\n",
    "                'train_score': score.mean(),\n",
    "                'valid_score': valid_score\n",
    "            })\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error with params {params}: {str(e)}\")\n",
    "            res.append({\n",
    "                **(dict(zip(param_grid.keys(), params))),\n",
    "                'train_score': 'Na',\n",
    "                'valid_score': 'Na'\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "    return pd.DataFrame(res).sort_values('valid_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "979d1b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSelection:\n",
    "    def __init__ (self,grids, grid_dict):\n",
    "        self.grids=grids\n",
    "        self.grid_dict=grid_dict\n",
    "        self.results=[]\n",
    "    def choose(self,X_train, y_train, X_valid, y_valid):\n",
    "        \"\"\"\n",
    "        Method `choose()` takes `X_train`, `y_train`, `X_valid`, `y_valid` \n",
    "        and returns the name of the best classifier among all the models on the validation set\n",
    "        \"\"\"\n",
    "        best_score=-1\n",
    "        for gs in self.grids:\n",
    "            model_name= self.grid_dict[self.grids.index(gs)]\n",
    "            print('Estimator: ', model_name)\n",
    "            grid_res=manual_grid_search(X_train,y_train,gs,X_valid, y_valid)\n",
    "            best_params = grid_res.drop([\"train_score\",\"valid_score\"], axis=1).to_dict('records')[0]\n",
    "            print(\"huuy\\n\",best_params)\n",
    "            train_score = grid_res.head(1)['train_score'].item()\n",
    "            best_valid_score = grid_res.head(1)['valid_score'].item()\n",
    "            self.results.append({\n",
    "                'model': model_name,\n",
    "                'params': best_params,\n",
    "                'valid_score': best_valid_score,\n",
    "                'train_score': train_score\n",
    "            })\n",
    "            \n",
    "            print(f\"Best params: {best_params}\")\n",
    "            print(f\"training accuracy: {train_score:.3f}\")\n",
    "            print(f\"Best on validation set accuracy score: {best_valid_score:.3f}\")\n",
    "            \n",
    "            if best_valid_score > best_score:\n",
    "                best_score = best_valid_score\n",
    "                best_model_name = model_name\n",
    "        print(f\"\\nBest model: {best_model_name}\")\n",
    "        return best_model_name\n",
    "    def best_results(self):\n",
    "        df = pd.DataFrame(self.results)\n",
    "        return df[['model', 'params', 'valid_score']].sort_values('valid_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92c7822",
   "metadata": {},
   "source": [
    "#### Finalization\n",
    "Takes an estimator.Method ```final_score()``` takes ```X_train, y_train, X_test, y_test``` and returns the accuracy\n",
    "\n",
    "Method ```save_model()``` takes a path, saves the model to this path and prints that the model was successfully saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "18ea1630",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "class Finalize():\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "    def final_score(self,X_train, y_train, X_test, y_test):\n",
    "        self.estimator.fit(X_train, y_train)\n",
    "        score=accuracy_score(y_test, self.estimator.predict(X_test))\n",
    "        print(\"Accuracy of the final model is\",score)\n",
    "        return score\n",
    "    def save_model(self,filename):\n",
    "        dump(self.estimator, f\"{filename}.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68c03e3",
   "metadata": {},
   "source": [
    "MAIN PROGGRAM LATER..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9ee75d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
